[
  {
    "objectID": "program.html#day-1-video",
    "href": "program.html#day-1-video",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "1 Day 1 (video)",
    "text": "1 Day 1 (video)\n\n\n1.1 Aditional resources\n\n1.1.1 Readings\n\nAlston, J. M., & Rick, J. A. (2021). A beginner’s guide to conducting reproducible research. Bulletin of the Ecological Society of America, 102(2), 1-14.\nCulina, A., van den Berg, I., Evans, S., & Sánchez-Tójar, A. (2020). Low availability of code in ecology: A call for urgent action. PLoS Biology, 18(7), e3000763.\nKöhler, J., Jansen, M., Rodríguez, A., Kok, P. J. R., Toledo, L. F., Emmrich, M., … & Vences, M. (2017). The use of bioacoustics in anuran taxonomy: theory, terminology, methods and recommendations for best practice. Zootaxa, 4251(1), 1-124. (at least the first 28 pages)\n\n\n\n1.1.2 Videos\n\nIntroduction to digital audio\nDigital audio artifacts: (Video 1, Video 2)\n\n\n\n \nIntroduction Introduction\n\nHow animal acoustic signals look like?\nAnalytical workflow in bioacoustics research\nAdvantages of programming\nCourse outline\n\n \nWhat is sound? Sound\n\n\nCreate a Rstudio project for the course\nDownload this folder into the course project directory\n\n\n\nSound as a time series\nSound as a digital object\nAcoustic data in R\n‘wave’ object structure\n‘wave’ object manipulations\nadditional formats\n\n \n\n1.2 Homework\n\nUse the function query_xenocanto() from the suwo package to check the availability of recordings for any bird species (do not download at this step) (check this brief tutorial on how to do that)\nSubset the data frame returned by the function to get a subset of subspecies/populations or recordings from a specific country and for certain vocalization type (using base R subsetting tools)\nDownload the associated recordings using query_xenocanto() again\nExplore the recordings with any spectrogram creating GUI program"
  },
  {
    "objectID": "program.html#day-2-video",
    "href": "program.html#day-2-video",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "2 Day 2 (video)",
    "text": "2 Day 2 (video)\n\n\n2.1 Additional resources\n\n2.1.1 Raven tutorials\n\nIntroduction to the Raven Pro Interface\nIntroduction to selections and measurements\nSaving, retrieving, and exporting selection tables\nUsing annotations\n\n\n\nBuilding spectrograms Building spectrograms\n\nFourier transform\nBuilding a spectrogram\nCharacteristics and limitations\nSpectrograms in R\n\nPackage seewave seewave\n\nExplore, modify and measure ‘wave’ objects\nSpectrograms and oscillograms\nFiltering and re-sampling\nAcoustic measurements\n\n \n\n2.2 Homework\n\nUse Raven Pro to annotate some of the signals found in the xeno-canto recordings you downloaded previously"
  },
  {
    "objectID": "program.html#day-3",
    "href": "program.html#day-3",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "3 Day 3",
    "text": "3 Day 3\n\n\n3.1 Additional resources\n\n3.1.1 Readings\n\nArasco, A. G., Manser, M., Watson, S. K., Kyabulima, S., Radford, A. N., Cant, M. A., & Garcia, M. (2024). Testing the acoustic adaptation hypothesis with vocalizations from three mongoose species. Animal Behaviour, 187, 71-95.\n\n\n\n \nAnnotation software annotations\n\nRaven / audacity\nOpen and explore recordings\nModify-optimize visualization parameters\nAnnotate signals\n\nQuantifying acoustic signal structure Quantify structure\n\nSpectro-temporal measurements (spectro_analysis())\nParameter description\nHarmonic content\nCepstral coefficients (mfcc_stats())\nCross-correlation (cross_correlation())\nDynamic time warping (freq_DTW())\nSignal-to-noise ratio (sig2noise())\nInflections (inflections())\nParameters at other levels (song_analysis())\n\n \n\n3.2 Homework\n\nDouble-check annotations using warbleR’s dedicated functions\n\n\nCreate single spectrograms of each annotation\nCreate full spectrograms of all sound files along with annotations\nCreate catalogs\n\n \n\nDouble-check annotations using Raven (export data from R to Raven)"
  },
  {
    "objectID": "program.html#day-4",
    "href": "program.html#day-4",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "4 Day 4",
    "text": "4 Day 4\n\n\n4.1 Additional resources\n\n4.1.1 Readings\n\nOdom, K. J., Cain, K. E., Hall, M. L., Langmore, N. E., Mulder, R. A., Kleindorfer, S., … & Webster, M. S. (2021). Sex role similarity and sexual selection predict male and female song elaboration and dimorphism in fairy‐wrens. Ecology and evolution, 11(24), 17901-17919.\n\n\n\n \nQuality control in recordings and annotations Quality checks\n\nCheck and modify sound file format (check_wavs(), info_wavs(), duration_wavs(), mp32wav() y fix_wavs())\nTuning spectrogram parameters (tweak_spectro())\nDouble-checking selection tables (check_sels(), spectrograms(), full_spectrograms() & catalog())\nRe-adjusting selections (tailor_sels())\n\nCharacterizing hierarchical levels in acoustic signals\n\nCreating ‘song’ spectrograms (full_spectrograms(), spectrograms())\n‘Song’ parameters (song_analysis())\n\n \n\n4.2 Homework\n\nSelect best quality signals for analysis\nMeasure acoustic parameters\nSummarize variation at higher hierachical levels (if necessary)"
  },
  {
    "objectID": "program.html#day-5",
    "href": "program.html#day-5",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "5 Day 5",
    "text": "5 Day 5\n\n\n5.1 Additional resources\n\n5.1.1 Readings\n\nBlog post: Potential issues of the ‘spectral parameters/PCA’ approach\nBlog post: Choosing the right method for measuring acoustic signal structure\n\n\n\n \nChoosing the right method for quantifying structure Comparing methods\n\nCompare different methods for quantifying structure (compare_methods())\n\nQuantifying acoustic spaces Acoustic space\n\nIntro to PhenotypeSpace\nQuanitfying space size\nComparing sub-spaces"
  },
  {
    "objectID": "sound.html",
    "href": "sound.html",
    "title": "Sound",
    "section": "",
    "text": "Sound waves are characterized by compression and expansion of the medium as sound energy moves through it. There is also back and forth motion of the particles making up the medium:\ntaken from https://dosits.org\nThe variation in pressure that is perceived at a fixed point in space can be represented by a graph of pressure (amplitude) by time:\nSounds waves are typically quantified by their frequency (number of cycles per second, Hz) and amplitude (relative intensity)."
  },
  {
    "objectID": "sound.html#objetives",
    "href": "sound.html#objetives",
    "title": "Sound",
    "section": "Objetives",
    "text": "Objetives\n\nLearn the basic aspects of sound as a physical phenomenom\nGet familiar with how sound is represented as a digital object in R"
  },
  {
    "objectID": "sound.html#sampling-frequency",
    "href": "sound.html#sampling-frequency",
    "title": "Sound",
    "section": "0.1 Sampling frequency",
    "text": "0.1 Sampling frequency\nDigitizing implies discretizing, which requires some sort of regular sampling. Sampling frequency refers to how many samples of the pressure level of the environment are taken per second. A 440 Hz sine wave recorded at 44100 Hz would have around 100 samples per cycle. This plot shows 2 cycles of a 440 Hz sine wave sampled (vertical dotted lines) at 44100 Hz:"
  },
  {
    "objectID": "sound.html#nyquist-frequency",
    "href": "sound.html#nyquist-frequency",
    "title": "Sound",
    "section": "0.2 Nyquist frequency",
    "text": "0.2 Nyquist frequency\nSampling should be good enough so the regularity of the sine wave can be reconstructed from the sampled data. Low sampling frequencies of a high frequency sine wave might not be able to provide enough information. For instance, the same 440 Hz sine wave sampled at 22050 Hz looks like this:\n\n\n\n\n\n\n\n\n\n \nAs you can see way less samples are taken per unit of time. The threshold at which samples cannot provide a reliable estimate of the regularity of a sine wave is called Nyquist frequency and corresponds to half of the frequency of the sine wave. This is how the 2 cycles of the 440 Hz would look like when sampled at its Nyquist frequency (sampling frequency of 880 Hz):"
  },
  {
    "objectID": "sound.html#quantization",
    "href": "sound.html#quantization",
    "title": "Sound",
    "section": "0.3 Quantization",
    "text": "0.3 Quantization\nOnce we know at which point amplitude samples will be taken we just need to measure it. This process is called quantization. The range of amplitude values is discretized in a number of intervals equals to 2 ^ bits. Hence, it involves some rounding of the actual amplitude values and some data loss. This is the same 440 Hz sine wave recorded at 44100 kHz quantized at 2 bits (2^2 = 4 intervals):\n\n\n\n\n\n\n\n\n\n \nRounding and data loss is more obvious if we add lines to the sampled points:\n\n\n\n\n\n\n\n\n\n \nThis is the same signal quantized at 3 bits (2^3 = 8 intervals):\n\n\n\n\n\n\n\n\n\n \n4 bits (2^4 = 16 intervals):\n\n\n\n\n\n\n\n\n\n \n.. and 8 bits (2^8 = 256 intervals):\n\n\n\n\n\n\n\n\n\n \nAt this point quantization involves very little information loss. 16 bits is probably the most common dynamic range used nowadays. As you can imagine, the high number of intervals (2^16 = 65536) allows for great precision in the quantization of amplitude."
  },
  {
    "objectID": "sound.html#non-specific-classes",
    "href": "sound.html#non-specific-classes",
    "title": "Sound",
    "section": "1.1 Non-specific classes",
    "text": "1.1 Non-specific classes\n\n1.1.1 Vectors\nAny numerical vector can be treated as a sound if a sampling frequency is provided. For example, a 440 Hz sinusoidal sound sampled at 8000 Hz for one second can be generated like this:\n\n\nCode\nlibrary(seewave)\n\n# create sinewave at 440 Hz\ns1 &lt;- sin(2 * pi * 440 * seq(0, 1, length.out = 8000))\n\nis.vector(s1)\n\n\n[1] TRUE\n\n\nCode\nmode(s1)\n\n\n[1] \"numeric\"\n\n\n \nThese sequences of values only make sense when specifying the sampling rate at which they were created:\n\n\nCode\noscillo(s1, f = 8000, from = 0, to = 0.01)\n\n\n\n\n\n\n\n\n\n \n\n\n1.1.2 Matrices\nYou can read any single column matrix:\n\n\nCode\ns2 &lt;- as.matrix(s1)\n\nis.matrix(s2)\n\n\n[1] TRUE\n\n\nCode\ndim(s2)\n\n\n[1] 8000    1\n\n\nCode\noscillo(s2, f = 8000, from = 0, to = 0.01)\n\n\n\n\n\n\n\n\n\n \nIf the matrix has more than one column, only the first column will be considered:\n\n\nCode\nx &lt;- rnorm(8000)\n\ns3 &lt;- cbind(s2, x)\n\nis.matrix(s3)\n\n\n[1] TRUE\n\n\nCode\ndim(s3)\n\n\n[1] 8000    2\n\n\nCode\noscillo(s3, f = 8000, from = 0, to = 0.01)\n\n\n\n\n\n\n\n\n\n \n\n\n1.1.3 Time series\nThe class ts and related functions ts(), as.ts(), is.ts() can also be used to generate sound objects in R. Here the command to similarly generate a series of time is shown corresponding to a 440 Hz sinusoidal sound sampled at 8000 Hz for one second:\n\n\nCode\ns4 &lt;- ts(data = s1, start = 0, frequency = 8000)\n\nstr(s4)\n\n\n Time-Series [1:8000] from 0 to 1: 0 0.339 0.637 0.861 0.982 ...\n\n\n \nTo generate a random noise of 0.5 seconds:\n\n\nCode\ns4 &lt;- ts(data = runif(4000, min = -1, max = 1), start = 0, end = 0.5, frequency = 8000)\n\nstr(s4)\n\n\n Time-Series [1:4001] from 0 to 0.5: -0.2992 0.9587 -0.8343 0.7967 -0.0124 ...\n\n\n \nThe frequency() and deltat() functions return the sampling frequency (\\(f\\)) and the time resolution (\\(Delta t\\)) respectively:\n\n\nCode\nfrequency(s4)\n\n\n[1] 8000\n\n\nCode\ndeltat(s4)\n\n\n[1] 0.000125\n\n\n \nAs the frequency is incorporated into the ts objects, it is not necessary to specify it when used within functions dedicated to audio:\n\n\nCode\noscillo(s4, from = 0, to = 0.01)\n\n\n\n\n\n\n\n\n\n \nIn the case of multiple time series, seewave functions will consider only the first series:\n\n\nCode\ns5 &lt;- ts(data = s3, f = 8000)\n\nclass(s5)\n\n\n[1] \"mts\"    \"ts\"     \"matrix\" \"array\" \n\n\nCode\noscillo(s5, from = 0, to = 0.01)"
  },
  {
    "objectID": "sound.html#dedicated-r-classes-for-sound",
    "href": "sound.html#dedicated-r-classes-for-sound",
    "title": "Sound",
    "section": "1.2 Dedicated R classes for sound",
    "text": "1.2 Dedicated R classes for sound\nThere are 3 kinds of objects corresponding to the wav binary format or themp3 compressed format:\n\nWave class of the package tuneR\nsound class of the package phonTools\nAudioSample class of the package audio\n\n \n\n1.2.1 Wave class (tuneR)\nThe Wave class comes with the tuneR package. This S4 class includes different “slots” with the amplitude data (left or right channel), the sampling frequency (or frequency), the number of bits (8/16/24/32) and the type of sound (mono/stereo). High sampling rates (&gt; 44100 Hz) can be read on these types of objects.\nThe function to import .wav files from the hard drive is readWave:\n\n\nCode\n# load packages\nlibrary(tuneR)\n\ns6 &lt;- readWave(\"./examples/Phae.long1.wav\")\n\n\n \nWe can verify the class of the object like this:\n\n\nCode\n# object class\nclass(s6)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\n \nS4 objects have a structure similar to lists but use ‘@’ to access each position (slot):\n\n\nCode\n# structure\nstr(s6)\n\n\nFormal class 'Wave' [package \"tuneR\"] with 6 slots\n  ..@ left     : int [1:56251] 162 -869 833 626 103 -2 43 19 47 227 ...\n  ..@ right    : num(0) \n  ..@ stereo   : logi FALSE\n  ..@ samp.rate: int 22500\n  ..@ bit      : int 16\n  ..@ pcm      : logi TRUE\n\n\nCode\n# extract 1 position\ns6@samp.rate\n\n\n[1] 22500\n\n\n \n\n“Pulse-code modulation (PCM) is a method used to digitally represent sampled analog signals. It is the standard form of digital audio. In a PCM stream, the amplitude of the analog signal is sampled regularly at uniform intervals, and each sample is quantized to the nearest value within a range of digital steps” (Wikipedia).\n\n \nThe samples come in the slot ‘@left’:\n\n\nCode\n# samples\ns6@left[1:40]\n\n\n [1]  162 -869  833  626  103   -2   43   19   47  227   -4  205  564  171  457\n[16]  838 -216   60   76 -623 -213  168 -746 -248  175 -512  -58  651  -85 -213\n[31]  586   40 -407  371  -51 -587  -92   94 -527   40\n\n\n \nThe number of samples is given by the duration and the sampling rate.\n \n\nExercise\n\nHow can we calculate the duration of the wave object using the information in the object?\n\n \n\nExtract the first second of audio from the object s6 using indexing (and squared brackets)\n\n\n \nAn advantage of using readWave() is the ability to read specific segments of sound files, especially useful with long files. This is done using the from andto arguments and specifying the units of time with the units arguments. The units can be converted into “samples”, “minutes” or “hours”. For example, to read only the section that begins in 1s and ends in 2s of the file “Phae.long1.wav”:\n\n\nCode\ns7 &lt;- readWave(\"./examples/Phae.long1.wav\", from = 1, to = 2, units = \"seconds\")\n\ns7\n\n\n\nWave Object\n    Number of Samples:      22500\n    Duration (seconds):     1\n    Samplingrate (Hertz):   22500\n    Channels (Mono/Stereo): Mono\n    PCM (integer format):   TRUE\n    Bit (8/16/24/32/64):    16 \n\n\n \nThe .mp3 files can be imported to R although they are imported inWave format. This is done using the readMP3() function:\n\n\nCode\ns7 &lt;- readMP3(\"./examples/Phae.long1.mp3\")\n\ns7\n\n\n\nWave Object\n    Number of Samples:      56448\n    Duration (seconds):     2.56\n    Samplingrate (Hertz):   22050\n    Channels (Mono/Stereo): Mono\n    PCM (integer format):   TRUE\n    Bit (8/16/24/32/64):    16 \n\n\n \nTo obtain information about the object (sampling frequency, number of bits, mono/stereo), it is necessary to use the indexing of S4 class objects:\n\n\nCode\ns7@samp.rate\n\n\n[1] 22050\n\n\nCode\ns7@bit\n\n\n[1] 16\n\n\nCode\ns7@stereo\n\n\n[1] FALSE\n\n\n \nA property that does not appear in these calls is that readWave does not normalize the sound. The values that describe the sound will be included between \\(\\pm2^{bit} - 1\\):\n\n\nCode\nrange(s7@left)\n\n\n[1] -32768  32767\n\n\n \n\nExercise\nThe function Wave can be used to create wave objects.\n \n\nRun the example code in the function documentation\nPlot the oscillogram for the first 0.01 s of ‘Wobj’\nNote that the function sine provides a shortcut that can be used to create wave object with a sine wave. Check out other similar functions described in the sine function documentation. Try 4 of these alternative functions and plot the oscillogram of the first 0.01 s for each of them.\n\n\n \nThe function read_sound_files from warbleR is a wrapper over several sound file reading functions, that can read files in ‘wav’, ‘mp3’, ‘flac’ and ‘wac’ format:\n\n\nCode\nlibrary(warbleR)\n\n# wave\nrsf1 &lt;- read_sound_file(\"Phaethornis-eurynome-15607.wav\", path = \"./examples\")\n\nclass(rsf1)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\nCode\n# mp3\nrsf2 &lt;- read_sound_file(\"Phaethornis-striigularis-154074.mp3\", path = \"./examples\")\n\nclass(rsf2)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\nCode\n# flac\nrsf3 &lt;- read_sound_file(\"Phae.long1.flac\", path = \"./examples\")\n\nclass(rsf3)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\nCode\n# wac\nrsf4 &lt;- read_sound_file(\"recording_20170716_230503.wac\", path = \"./examples\")\n\nclass(rsf4)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\n \nThe function can also read recordings hosted in an online repository:\n\n\nCode\nrsf5 &lt;- read_sound_file(X = \"https://xeno-canto.org/35340/download\")\n\nclass(rsf5)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\nCode\nrsf6 &lt;- read_sound_file(X = \"https://github.com/maRce10/OTS_BIR_2024/raw/master/examples/Phae.long1.flac\")\n\nclass(rsf6)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\""
  },
  {
    "objectID": "sound.html#class-sound-phontools",
    "href": "sound.html#class-sound-phontools",
    "title": "Sound",
    "section": "1.3 Class sound (phonTools)",
    "text": "1.3 Class sound (phonTools)\nThe loadsound() function of phonTools also imports ‘wave’ sound files into R, in this case as objects of class sound:\n\n\nCode\nlibrary(phonTools)\n\ns8 &lt;- loadsound(\"./examples/Phae.long1.wav\")\n\ns8\n\n\n\n      Sound Object\n\n   Read from file:         ./examples/Phae.long1.wav\n   Sampling frequency:     22500  Hz\n   Duration:               2500.044  ms\n   Number of Samples:      56251 \n\n\nCode\nstr(s8)\n\n\nList of 5\n $ filename  : chr \"./examples/Phae.long1.wav\"\n $ fs        : int 22500\n $ numSamples: num 56251\n $ duration  : num 2500\n $ sound     : Time-Series [1:56251] from 0 to 2.5: 0.00494 -0.02652 0.02542 0.0191 0.00314 ...\n - attr(*, \"class\")= chr \"sound\"\n\n\n \nThis function only imports files with a dynamic range of 8 or 16 bits."
  },
  {
    "objectID": "sound.html#class-audiosample-audio",
    "href": "sound.html#class-audiosample-audio",
    "title": "Sound",
    "section": "1.4 Class audioSample (audio)",
    "text": "1.4 Class audioSample (audio)\nThe audio package is another option to handle .wav files. The sound can be imported using the load.wave() function. The class of the resulting object is audioSample which is essentially a numerical vector (for mono) or a numerical matrix with two rows (for stereo). The sampling frequency and resolution are saved as attributes:\n\n\nCode\nlibrary(audio)\n\ns10 &lt;- load.wave(\"./examples/Phae.long1.wav\")\n\nhead(s10)\n\n\nsample rate: 22500Hz, mono, 16-bits\n[1]  4.943848e-03 -2.652058e-02  2.542114e-02  1.910400e-02  3.143311e-03\n[6] -6.103702e-05\n\n\nCode\ns10$rate\n\n\n[1] 22500\n\n\nCode\ns10$bits\n\n\n[1] 16\n\n\n \nThe main advantage of the audio package is that the sound can be acquired directly within an R session. This is achieved first by preparing a NAs vector and then using therecord() function. For example, to obtain a mono sound of 5 seconds sampled at 16 kHz:\n\n\nCode\ns11 &lt;- rep(NA_real_, 16000 * 5)\n\nrecord(s11, 16000, 1)\n\n\n \nA recording session can be controlled by three complementary functions: pause(), rewind(), and resume()."
  },
  {
    "objectID": "sound.html#export-sounds-from-r",
    "href": "sound.html#export-sounds-from-r",
    "title": "Sound",
    "section": "1.5 Export sounds from R",
    "text": "1.5 Export sounds from R\nFor maximum compatibility with other sound programs, it may be useful to save a sound as a simple .txt file. The following commands will write a “tico.txt” file:\n\n\nCode\ndata(tico)\n\nexport(tico, f = 22050)"
  },
  {
    "objectID": "sound.html#format-.wav",
    "href": "sound.html#format-.wav",
    "title": "Sound",
    "section": "1.6 Format ‘.wav’",
    "text": "1.6 Format ‘.wav’\ntuneR and audio have a function to write .wav files: writeWave() and save.wave() respectively. Within seewave, the savewav() function, which is based on writeWave(), can be used to save data in .wav format. By default, the object name will be used for the name of the .wav file:\n\n\nCode\nsavewav(tico)"
  },
  {
    "objectID": "sound.html#format-.flac",
    "href": "sound.html#format-.flac",
    "title": "Sound",
    "section": "1.7 Format ‘.flac’",
    "text": "1.7 Format ‘.flac’\nFree Lossless Audio Codec (FLAC) is a file format for lossless audio data compression. FLAC reduces bandwidth and storage requirements without sacrificing the integrity of the audio source. Audio sources encoded in FLAC are generally reduced in size from 40 to 50 percent. See the flac website for more details (flac.sourceforge.net).\nThe .flac format cannot be used as such with R. However, the wav2flac()function allows you to call the FLAC software directly from the console. Therefore, FLAC must be installed on your operating system. If you have a .wav file that you want to compress in .flac, call:\n\n\nCode\nwav2flac(file = \"./examples/Phae.long1.wav\", overwrite = FALSE)\n\n\n \nTo compress a .wav file to a .flac format, the argument reverse = TRUE must be used:\n\n\nCode\nwav2flac(\"Phae.long1.flac\", reverse = TRUE)\n\n\n \nThis table, taken from Sueur (2018), summarizes the functions available to import and export sound files in R. The table is incomplete since it does not mention the functions of the phonTools package:\n\n\n \n\nExercise\n\nHow does the sampling rate affect the size of an audio file? (hint: create 2 sounds files with the same data but different sampling rates; use sine())\nHow does the dynamic range affect the size of an audio file?\nUse the system.time() function to compare the performance of the different functions to import audio files in R. For this use the file “LBH.374.SUR.wav” (Long-billed hermit songs) which lasts about 2 min\n\nThe following code creates a plot similar to oscillo but using dots instead of lines:\n\n\nCode\n# generate sine wave\nwav &lt;- sine(freq = 440, duration = 500, xunit = \"samples\", samp.rate = 44100)\n\n# plot\nplot(wav@left)\n\n\n\n\n\n\n\n\n\n\n\n \n\nUse the function downsample() to reduce the sampling rate of ‘wav’ (below 44100) and plot the output object. Decrease the sampling rate until you cannot recognize the wave pattern from the original wave object. Try several values so you get a sense at which sampling rate this happens."
  },
  {
    "objectID": "sound.html#references",
    "href": "sound.html#references",
    "title": "Sound",
    "section": "1.8 References",
    "text": "1.8 References\n\nSueur J, Aubin T, Simonis C. 2008. Equipment review: seewave, a free modular tool for sound analysis and synthesis. Bioacoustics 18(2):213–226.\nSueur, J. (2018). Sound Analysis and Synthesis with R.\nSueur J. (2018). I/O of sound with R. seewave package vignette. url: https://cran.r-project.org/web/packages/seewave/vignettes/seewave_IO.pdf\n\n\nSession information\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.2 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: America/Costa_Rica\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] audio_0.1-11       phonTools_0.2-2.2  warbleR_1.1.30     NatureSounds_1.0.4\n[5] tuneR_1.4.6        knitr_1.46         seewave_2.2.3     \n\nloaded via a namespace (and not attached):\n [1] viridis_0.6.5      utf8_1.2.4         generics_0.1.3     bitops_1.0-7      \n [5] stringi_1.8.3      digest_0.6.35      magrittr_2.0.3     evaluate_0.23     \n [9] grid_4.3.2         fastmap_1.1.1      jsonlite_1.8.8     brio_1.1.4        \n[13] formatR_1.14       gridExtra_2.3      fansi_1.0.6        viridisLite_0.4.2 \n[17] scales_1.3.0       pbapply_1.7-2      cli_3.6.2          rlang_1.1.3       \n[21] fftw_1.0-8         munsell_0.5.0      withr_3.0.0        yaml_2.3.8        \n[25] tools_4.3.2        parallel_4.3.2     dplyr_1.1.4        colorspace_2.1-0  \n[29] ggplot2_3.5.1      bioacoustics_0.2.8 vctrs_0.6.5        R6_2.5.1          \n[33] proxy_0.4-27       lifecycle_1.0.4    dtw_1.23-1         stringr_1.5.1     \n[37] htmlwidgets_1.6.4  MASS_7.3-55        pkgconfig_2.0.3    pillar_1.9.0      \n[41] gtable_0.3.4       moments_0.14.1     glue_1.7.0         Rcpp_1.0.12       \n[45] xfun_0.43          tibble_3.2.1       tidyselect_1.2.0   rstudioapi_0.15.0 \n[49] rjson_0.2.21       htmltools_0.5.8.1  rmarkdown_2.26     testthat_3.2.1    \n[53] signal_1.8-0       compiler_4.3.2     RCurl_1.98-1.14"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "",
    "text": "Bioacoustic Analysis in R\n\n\nOrganization for Tropical Studies\n\n\n\nMarcelo Araya-Salas, PhD\n\n\n\nMay 13 - 17, 2024\n\n\n\n\nThe study of animal acoustic signals is a central tool for many fields in behavior, ecology, evolution and biodiversity monitoring. The accessibility of recording equipment and growing availability of open-access acoustic libraries provide an unprecedented opportunity to study animal acoustic signals at large temporal, geographic and taxonomic scales. However, the diversity of analytical methods and the multidimensionality of these signals posts significant challenges to conduct analyses that can quantify biologically meaningful variation. The recent development of acoustic analysis tools in the R programming environment provides a powerful means for overcoming these challenges, facilitating the gathering and organization of large acoustic data sets and the use of more elaborated analyses that better fit the studied acoustic signals and associated biological questions. The course will introduce students on the basic concepts in animal acoustic signal research as well as hands-on experience on analytical tools in R.\n\nObjetive\nTraining biological science students and researchers in the detection and analysis of animal sounds in R. Specifically, it seeks to familiarize participants with computational tools in the R environment aiming at curating, detecting and analyzing animal acoustic signals, with an especial focus on quantifying fine-scale structural variation. The course will introduce the most relevant acoustics concepts to allow a detailed understanding of the metrics used for characterize acoustic signals. It will also guide participants through a variety of R packages for bioacoustics analysis, including seewave, tuneR, warbleR and baRulho."
  },
  {
    "objectID": "course_prep.html",
    "href": "course_prep.html",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "",
    "text": "Install or update R on the computer you will use during the course (https://cran.r-project.org). I assume that you already have it installed, but try to update it if you have a R version &lt; 4.0.0. You can find which R version you have by running this in the R console:\n\n\nversion$version.string\n\n\nUpdate all R packages if you already had R installed (⚠️ this step can take a long time to run ⚠️):\n\n\nupdate.packages(ask = FALSE)\n\n\nInstall or update the RStudio interface (https://www.rstudio.com/products/rstudio/download/, choose the free version). Optional but advised.\nMake a directory called “BIR_OTS_2024”, this will be your working directory for the course.\nOpen RStudio and select the tab “Tools” then “Global Options” (last option). Select the “Code” option, then select the box for “Soft-wrap R source files”.\nAlso in Rstudio: Select the “Pane Layout” option and move “Source” to the top left pane and “Console” to the top right pane. For those of you unfamiliar with RStudio, the source is your script, where you save code in a physical file (usually .R script) and the console prints the output of the code you run from the source. You can write code in the console, but it will not be saved in a physical file. This layout allocates more screen space to the most useful panes. Hit “Apply” and “Ok”.\nAlso in Rstudio: Go back up to the “File” tab and select “New Project”, then select the “BIR_OTS_2024” directory.\nNow in the R console in Rstudio: Run the following code to install the latest developmental versions (from github) of warbleR, Rraven, PhenotypeSpace, ohun, baRulho and dynaSpec (remove the packages first if you have them installed already).\n\n\n# package to install other packages from github\nif (!requireNamespace(\"sketchy\"))\n  install.packages(\"sketchy\") \n\n# load package\nlibrary(sketchy)\n\n# install/load packages\nload_packages(packages = c(\n  \"pracma\",\n  \"Sim.DiffProc\",\n  \"bioacoustics\",\n  \"phonTools\",\n  \"soundgen\",\n  \"audio\",\n  github = \"maRce10/warbleR\",\n  github = \"maRce10/Rraven\",\n  github = \"maRce10/ohun\",\n  github = \"maRce10/suwo\",\n  github = \"maRce10/baRulho\",\n  github = \"maRce10/dynaSpec\"\n )\n)\n\nif you have any issue installing ‘bioacoustics’ take a look at this fix: https://stackoverflow.com/questions/53092646/unable-to-install-warbler-package-using-mac-os\n\nWe also need to install the package PhenotypeSpace, which requires some dependencies that have been archived in CRAN. So to install it please first download this two package tar.gz files and install them manually:\n\n\nrgeos_0.6-4.tar.gz\nspatstat.core_2.4-4.tar.gz\n\nOnce you have install them you can install PhenotypeSpace:\n\n# install/load package\nload_packages(packages = c(github = \"maRce10/PhenotypeSpace\"))\n\n\nwarbleR depends heavily on the R package seewave. Seewave may require some extra steps to get installed. Take a look at seewave’s website for further help: http://rug.mnhn.fr/seewave (and then go to “installation” and scroll down)\nInstall Raven lite from ttp://ravensoundsoftware.com/raven-pricing/(scroll down to “Raven Lite 2.0” and click on “Order Free Raven Lite 2.0 License”). Ignore if you have any Raven version already installed.\nInstall ffmpeg (only needed for dynaSpec package, not critical):\n\nhttps://ffmpeg.org/download.html\ntake a look at this link if you have issues installing ffmpeg on windows:\nhttps://github.com/maRce10/dynaSpec/issues/3\n\nInstall Audacity (not critical, you can use Adobe Audition instead):\n\nhttps://www.audacityteam.org/download/\n\nInstall SOX. It can be downloaded from here (not critical but could be useful): http://sox.sourceforge.net (Not critical)\nInstall FLAC. It can be downloaded from here (also not critical): https://xiph.org/flac/download.html (Not critical)\nNote that you can also run the code using google colab. Take a look at this notebook: https://colab.research.google.com/\n\n \n\nA few tips to make sure you will take full advantage of the course:\n\nSet aside a physical space, hopefully as isolated as possible from external stimuli\nUse headphones/earphones to avoid any interference from echoes or external noises\nIdeally, read the materials ahead of time (I know! it’s time comsuming)\nMake sure you have anything you need before the start of the class\nBe ready a few minutes before the start of the class\nTry to focus as much as possible in the course, close other programs or unnecessary internet browser tabs (i.e. instagram, twitter, etc). This will also make the computer more efficient (less likely to get slow)\nComment your code"
  }
]