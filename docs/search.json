[
  {
    "objectID": "program.html#day-1-video",
    "href": "program.html#day-1-video",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "1 Day 1 (video)",
    "text": "1 Day 1 (video)\n\n\n1.1 Aditional resources\n\n1.1.1 Readings\n\nAlston, J. M., & Rick, J. A. (2021). A beginner’s guide to conducting reproducible research. Bulletin of the Ecological Society of America, 102(2), 1-14.\nCulina, A., van den Berg, I., Evans, S., & Sánchez-Tójar, A. (2020). Low availability of code in ecology: A call for urgent action. PLoS Biology, 18(7), e3000763.\nKöhler, J., Jansen, M., Rodríguez, A., Kok, P. J. R., Toledo, L. F., Emmrich, M., … & Vences, M. (2017). The use of bioacoustics in anuran taxonomy: theory, terminology, methods and recommendations for best practice. Zootaxa, 4251(1), 1-124. (at least the first 28 pages)\n\n\n\n1.1.2 Videos\n\nIntroduction to digital audio\nDigital audio artifacts: (Video 1, Video 2)\n\n\n\n \nIntroduction Introduction\n\nHow animal acoustic signals look like?\nAnalytical workflow in bioacoustics research\nAdvantages of programming\nCourse outline\n\n \nWhat is sound? Sound\n\n\nCreate a Rstudio project for the course\nDownload this folder into the course project directory\n\n\n\nSound as a time series\nSound as a digital object\nAcoustic data in R\n‘wave’ object structure\n‘wave’ object manipulations\nadditional formats\n\n \n\n1.2 Homework\n\nUse the function query_xenocanto() from the suwo package to check the availability of recordings for any bird species (do not download at this step) (check this brief tutorial on how to do that)\nSubset the data frame returned by the function to get a subset of subspecies/populations or recordings from a specific country and for certain vocalization type (using base R subsetting tools)\nDownload the associated recordings using query_xenocanto() again\nExplore the recordings with any spectrogram creating GUI program"
  },
  {
    "objectID": "program.html#day-2-video",
    "href": "program.html#day-2-video",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "2 Day 2 (video)",
    "text": "2 Day 2 (video)\n\n\n2.1 Additional resources\n\n2.1.1 Raven tutorials\n\nIntroduction to the Raven Pro Interface\nIntroduction to selections and measurements\nSaving, retrieving, and exporting selection tables\nUsing annotations\n\n\n\nBuilding spectrograms Building spectrograms\n\nFourier transform\nBuilding a spectrogram\nCharacteristics and limitations\nSpectrograms in R\n\nPackage seewave seewave\n\nExplore, modify and measure ‘wave’ objects\nSpectrograms and oscillograms\nFiltering and re-sampling\nAcoustic measurements\n\n \n\n2.2 Homework\n\nUse Raven Pro to annotate some of the signals found in the xeno-canto recordings you downloaded previously"
  },
  {
    "objectID": "program.html#day-3",
    "href": "program.html#day-3",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "3 Day 3",
    "text": "3 Day 3\n\n\n3.1 Additional resources\n\n3.1.1 Readings\n\nArasco, A. G., Manser, M., Watson, S. K., Kyabulima, S., Radford, A. N., Cant, M. A., & Garcia, M. (2024). Testing the acoustic adaptation hypothesis with vocalizations from three mongoose species. Animal Behaviour, 187, 71-95.\n\n\n\n \nAnnotation software annotations\n\nRaven / audacity\nOpen and explore recordings\nModify-optimize visualization parameters\nAnnotate signals\n\nQuantifying acoustic signal structure Quantify structure\n\nSpectro-temporal measurements (spectro_analysis())\nParameter description\nHarmonic content\nCepstral coefficients (mfcc_stats())\nCross-correlation (cross_correlation())\nDynamic time warping (freq_DTW())\nSignal-to-noise ratio (sig2noise())\nInflections (inflections())\nParameters at other levels (song_analysis())\n\n \n\n3.2 Homework\n\nDouble-check annotations using warbleR’s dedicated functions\n\n\nCreate single spectrograms of each annotation\nCreate full spectrograms of all sound files along with annotations\nCreate catalogs\n\n \n\nDouble-check annotations using Raven (export data from R to Raven)"
  },
  {
    "objectID": "program.html#day-4",
    "href": "program.html#day-4",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "4 Day 4",
    "text": "4 Day 4\n\n\n4.1 Additional resources\n\n4.1.1 Readings\n\nOdom, K. J., Cain, K. E., Hall, M. L., Langmore, N. E., Mulder, R. A., Kleindorfer, S., … & Webster, M. S. (2021). Sex role similarity and sexual selection predict male and female song elaboration and dimorphism in fairy‐wrens. Ecology and evolution, 11(24), 17901-17919.\n\n\n\n \nQuality control in recordings and annotations Quality checks\n\nCheck and modify sound file format (check_wavs(), info_wavs(), duration_wavs(), mp32wav() y fix_wavs())\nTuning spectrogram parameters (tweak_spectro())\nDouble-checking selection tables (check_sels(), spectrograms(), full_spectrograms() & catalog())\nRe-adjusting selections (tailor_sels())\n\nCharacterizing hierarchical levels in acoustic signals\n\nCreating ‘song’ spectrograms (full_spectrograms(), spectrograms())\n‘Song’ parameters (song_analysis())\n\n \n\n4.2 Homework\n\nSelect best quality signals for analysis\nMeasure acoustic parameters\nSummarize variation at higher hierachical levels (if necessary)"
  },
  {
    "objectID": "program.html#day-5",
    "href": "program.html#day-5",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "5 Day 5",
    "text": "5 Day 5\n\n\n5.1 Additional resources\n\n5.1.1 Readings\n\nBlog post: Potential issues of the ‘spectral parameters/PCA’ approach\nBlog post: Choosing the right method for measuring acoustic signal structure\n\n\n\n \nChoosing the right method for quantifying structure Comparing methods\n\nCompare different methods for quantifying structure (compare_methods())\n\nQuantifying acoustic spaces Acoustic space\n\nIntro to PhenotypeSpace\nQuanitfying space size\nComparing sub-spaces"
  },
  {
    "objectID": "sound.html",
    "href": "sound.html",
    "title": "Sound",
    "section": "",
    "text": "Sound waves are characterized by compression and expansion of the medium as sound energy moves through it. There is also back and forth motion of the particles making up the medium:\ntaken from https://dosits.org\nThe variation in pressure that is perceived at a fixed point in space can be represented by a graph of pressure (amplitude) by time:\nSounds waves are typically quantified by their frequency (number of cycles per second, Hz) and amplitude (relative intensity)."
  },
  {
    "objectID": "sound.html#objetives",
    "href": "sound.html#objetives",
    "title": "Sound",
    "section": "Objetives",
    "text": "Objetives\n\nLearn the basic aspects of sound as a physical phenomenom\nGet familiar with how sound is represented as a digital object in R"
  },
  {
    "objectID": "sound.html#sampling-frequency",
    "href": "sound.html#sampling-frequency",
    "title": "Sound",
    "section": "0.1 Sampling frequency",
    "text": "0.1 Sampling frequency\nDigitizing implies discretizing, which requires some sort of regular sampling. Sampling frequency refers to how many samples of the pressure level of the environment are taken per second. A 440 Hz sine wave recorded at 44100 Hz would have around 100 samples per cycle. This plot shows 2 cycles of a 440 Hz sine wave sampled (vertical dotted lines) at 44100 Hz:"
  },
  {
    "objectID": "sound.html#nyquist-frequency",
    "href": "sound.html#nyquist-frequency",
    "title": "Sound",
    "section": "0.2 Nyquist frequency",
    "text": "0.2 Nyquist frequency\nSampling should be good enough so the regularity of the sine wave can be reconstructed from the sampled data. Low sampling frequencies of a high frequency sine wave might not be able to provide enough information. For instance, the same 440 Hz sine wave sampled at 22050 Hz looks like this:\n\n\n\n\n\n\n\n\n\n \nAs you can see way less samples are taken per unit of time. The threshold at which samples cannot provide a reliable estimate of the regularity of a sine wave is called Nyquist frequency and corresponds to half of the frequency of the sine wave. This is how the 2 cycles of the 440 Hz would look like when sampled at its Nyquist frequency (sampling frequency of 880 Hz):"
  },
  {
    "objectID": "sound.html#quantization",
    "href": "sound.html#quantization",
    "title": "Sound",
    "section": "0.3 Quantization",
    "text": "0.3 Quantization\nOnce we know at which point amplitude samples will be taken we just need to measure it. This process is called quantization. The range of amplitude values is discretized in a number of intervals equals to 2 ^ bits. Hence, it involves some rounding of the actual amplitude values and some data loss. This is the same 440 Hz sine wave recorded at 44100 kHz quantized at 2 bits (2^2 = 4 intervals):\n\n\n\n\n\n\n\n\n\n \nRounding and data loss is more obvious if we add lines to the sampled points:\n\n\n\n\n\n\n\n\n\n \nThis is the same signal quantized at 3 bits (2^3 = 8 intervals):\n\n\n\n\n\n\n\n\n\n \n4 bits (2^4 = 16 intervals):\n\n\n\n\n\n\n\n\n\n \n.. and 8 bits (2^8 = 256 intervals):\n\n\n\n\n\n\n\n\n\n \nAt this point quantization involves very little information loss. 16 bits is probably the most common dynamic range used nowadays. As you can imagine, the high number of intervals (2^16 = 65536) allows for great precision in the quantization of amplitude."
  },
  {
    "objectID": "sound.html#non-specific-classes",
    "href": "sound.html#non-specific-classes",
    "title": "Sound",
    "section": "1.1 Non-specific classes",
    "text": "1.1 Non-specific classes\n\n1.1.1 Vectors\nAny numerical vector can be treated as a sound if a sampling frequency is provided. For example, a 440 Hz sinusoidal sound sampled at 8000 Hz for one second can be generated like this:\n\n\nCode\nlibrary(seewave)\n\n# create sinewave at 440 Hz\ns1 &lt;- sin(2 * pi * 440 * seq(0, 1, length.out = 8000))\n\nis.vector(s1)\n\n\n[1] TRUE\n\n\nCode\nmode(s1)\n\n\n[1] \"numeric\"\n\n\n \nThese sequences of values only make sense when specifying the sampling rate at which they were created:\n\n\nCode\noscillo(s1, f = 8000, from = 0, to = 0.01)\n\n\n\n\n\n\n\n\n\n \n\n\n1.1.2 Matrices\nYou can read any single column matrix:\n\n\nCode\ns2 &lt;- as.matrix(s1)\n\nis.matrix(s2)\n\n\n[1] TRUE\n\n\nCode\ndim(s2)\n\n\n[1] 8000    1\n\n\nCode\noscillo(s2, f = 8000, from = 0, to = 0.01)\n\n\n\n\n\n\n\n\n\n \nIf the matrix has more than one column, only the first column will be considered:\n\n\nCode\nx &lt;- rnorm(8000)\n\ns3 &lt;- cbind(s2, x)\n\nis.matrix(s3)\n\n\n[1] TRUE\n\n\nCode\ndim(s3)\n\n\n[1] 8000    2\n\n\nCode\noscillo(s3, f = 8000, from = 0, to = 0.01)\n\n\n\n\n\n\n\n\n\n \n\n\n1.1.3 Time series\nThe class ts and related functions ts(), as.ts(), is.ts() can also be used to generate sound objects in R. Here the command to similarly generate a series of time is shown corresponding to a 440 Hz sinusoidal sound sampled at 8000 Hz for one second:\n\n\nCode\ns4 &lt;- ts(data = s1, start = 0, frequency = 8000)\n\nstr(s4)\n\n\n Time-Series [1:8000] from 0 to 1: 0 0.339 0.637 0.861 0.982 ...\n\n\n \nTo generate a random noise of 0.5 seconds:\n\n\nCode\ns4 &lt;- ts(data = runif(4000, min = -1, max = 1), start = 0, end = 0.5, frequency = 8000)\n\nstr(s4)\n\n\n Time-Series [1:4001] from 0 to 0.5: -0.2992 0.9587 -0.8343 0.7967 -0.0124 ...\n\n\n \nThe frequency() and deltat() functions return the sampling frequency (\\(f\\)) and the time resolution (\\(Delta t\\)) respectively:\n\n\nCode\nfrequency(s4)\n\n\n[1] 8000\n\n\nCode\ndeltat(s4)\n\n\n[1] 0.000125\n\n\n \nAs the frequency is incorporated into the ts objects, it is not necessary to specify it when used within functions dedicated to audio:\n\n\nCode\noscillo(s4, from = 0, to = 0.01)\n\n\n\n\n\n\n\n\n\n \nIn the case of multiple time series, seewave functions will consider only the first series:\n\n\nCode\ns5 &lt;- ts(data = s3, f = 8000)\n\nclass(s5)\n\n\n[1] \"mts\"    \"ts\"     \"matrix\" \"array\" \n\n\nCode\noscillo(s5, from = 0, to = 0.01)"
  },
  {
    "objectID": "sound.html#dedicated-r-classes-for-sound",
    "href": "sound.html#dedicated-r-classes-for-sound",
    "title": "Sound",
    "section": "1.2 Dedicated R classes for sound",
    "text": "1.2 Dedicated R classes for sound\nThere are 3 kinds of objects corresponding to the wav binary format or themp3 compressed format:\n\nWave class of the package tuneR\nsound class of the package phonTools\nAudioSample class of the package audio\n\n \n\n1.2.1 Wave class (tuneR)\nThe Wave class comes with the tuneR package. This S4 class includes different “slots” with the amplitude data (left or right channel), the sampling frequency (or frequency), the number of bits (8/16/24/32) and the type of sound (mono/stereo). High sampling rates (&gt; 44100 Hz) can be read on these types of objects.\nThe function to import .wav files from the hard drive is readWave:\n\n\nCode\n# load packages\nlibrary(tuneR)\n\ns6 &lt;- readWave(\"./examples/Phae.long1.wav\")\n\n\n \nWe can verify the class of the object like this:\n\n\nCode\n# object class\nclass(s6)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\n \nS4 objects have a structure similar to lists but use ‘@’ to access each position (slot):\n\n\nCode\n# structure\nstr(s6)\n\n\nFormal class 'Wave' [package \"tuneR\"] with 6 slots\n  ..@ left     : int [1:56251] 162 -869 833 626 103 -2 43 19 47 227 ...\n  ..@ right    : num(0) \n  ..@ stereo   : logi FALSE\n  ..@ samp.rate: int 22500\n  ..@ bit      : int 16\n  ..@ pcm      : logi TRUE\n\n\nCode\n# extract 1 position\ns6@samp.rate\n\n\n[1] 22500\n\n\n \n\n“Pulse-code modulation (PCM) is a method used to digitally represent sampled analog signals. It is the standard form of digital audio. In a PCM stream, the amplitude of the analog signal is sampled regularly at uniform intervals, and each sample is quantized to the nearest value within a range of digital steps” (Wikipedia).\n\n \nThe samples come in the slot ‘@left’:\n\n\nCode\n# samples\ns6@left[1:40]\n\n\n [1]  162 -869  833  626  103   -2   43   19   47  227   -4  205  564  171  457\n[16]  838 -216   60   76 -623 -213  168 -746 -248  175 -512  -58  651  -85 -213\n[31]  586   40 -407  371  -51 -587  -92   94 -527   40\n\n\n \nThe number of samples is given by the duration and the sampling rate.\n \n\nExercise\n\nHow can we calculate the duration of the wave object using the information in the object?\n\n \n\nExtract the first second of audio from the object s6 using indexing (and squared brackets)\n\n\n \nAn advantage of using readWave() is the ability to read specific segments of sound files, especially useful with long files. This is done using the from andto arguments and specifying the units of time with the units arguments. The units can be converted into “samples”, “minutes” or “hours”. For example, to read only the section that begins in 1s and ends in 2s of the file “Phae.long1.wav”:\n\n\nCode\ns7 &lt;- readWave(\"./examples/Phae.long1.wav\", from = 1, to = 2, units = \"seconds\")\n\ns7\n\n\n\nWave Object\n    Number of Samples:      22500\n    Duration (seconds):     1\n    Samplingrate (Hertz):   22500\n    Channels (Mono/Stereo): Mono\n    PCM (integer format):   TRUE\n    Bit (8/16/24/32/64):    16 \n\n\n \nThe .mp3 files can be imported to R although they are imported inWave format. This is done using the readMP3() function:\n\n\nCode\ns7 &lt;- readMP3(\"./examples/Phae.long1.mp3\")\n\ns7\n\n\n\nWave Object\n    Number of Samples:      56448\n    Duration (seconds):     2.56\n    Samplingrate (Hertz):   22050\n    Channels (Mono/Stereo): Mono\n    PCM (integer format):   TRUE\n    Bit (8/16/24/32/64):    16 \n\n\n \nTo obtain information about the object (sampling frequency, number of bits, mono/stereo), it is necessary to use the indexing of S4 class objects:\n\n\nCode\ns7@samp.rate\n\n\n[1] 22050\n\n\nCode\ns7@bit\n\n\n[1] 16\n\n\nCode\ns7@stereo\n\n\n[1] FALSE\n\n\n \nA property that does not appear in these calls is that readWave does not normalize the sound. The values that describe the sound will be included between \\(\\pm2^{bit} - 1\\):\n\n\nCode\nrange(s7@left)\n\n\n[1] -32768  32767\n\n\n \n\nExercise\nThe function Wave can be used to create wave objects.\n \n\nRun the example code in the function documentation\nPlot the oscillogram for the first 0.01 s of ‘Wobj’\nNote that the function sine provides a shortcut that can be used to create wave object with a sine wave. Check out other similar functions described in the sine function documentation. Try 4 of these alternative functions and plot the oscillogram of the first 0.01 s for each of them.\n\n\n \nThe function read_sound_files from warbleR is a wrapper over several sound file reading functions, that can read files in ‘wav’, ‘mp3’, ‘flac’ and ‘wac’ format:\n\n\nCode\nlibrary(warbleR)\n\n# wave\nrsf1 &lt;- read_sound_file(\"Phaethornis-eurynome-15607.wav\", path = \"./examples\")\n\nclass(rsf1)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\nCode\n# mp3\nrsf2 &lt;- read_sound_file(\"Phaethornis-striigularis-154074.mp3\", path = \"./examples\")\n\nclass(rsf2)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\nCode\n# flac\nrsf3 &lt;- read_sound_file(\"Phae.long1.flac\", path = \"./examples\")\n\nclass(rsf3)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\nCode\n# wac\nrsf4 &lt;- read_sound_file(\"recording_20170716_230503.wac\", path = \"./examples\")\n\nclass(rsf4)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\n \nThe function can also read recordings hosted in an online repository:\n\n\nCode\nrsf5 &lt;- read_sound_file(X = \"https://xeno-canto.org/35340/download\")\n\nclass(rsf5)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\nCode\nrsf6 &lt;- read_sound_file(X = \"https://github.com/maRce10/OTS_BIR_2024/raw/master/examples/Phae.long1.flac\")\n\nclass(rsf6)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\""
  },
  {
    "objectID": "sound.html#class-sound-phontools",
    "href": "sound.html#class-sound-phontools",
    "title": "Sound",
    "section": "1.3 Class sound (phonTools)",
    "text": "1.3 Class sound (phonTools)\nThe loadsound() function of phonTools also imports ‘wave’ sound files into R, in this case as objects of class sound:\n\n\nCode\nlibrary(phonTools)\n\ns8 &lt;- loadsound(\"./examples/Phae.long1.wav\")\n\ns8\n\n\n\n      Sound Object\n\n   Read from file:         ./examples/Phae.long1.wav\n   Sampling frequency:     22500  Hz\n   Duration:               2500.044  ms\n   Number of Samples:      56251 \n\n\nCode\nstr(s8)\n\n\nList of 5\n $ filename  : chr \"./examples/Phae.long1.wav\"\n $ fs        : int 22500\n $ numSamples: num 56251\n $ duration  : num 2500\n $ sound     : Time-Series [1:56251] from 0 to 2.5: 0.00494 -0.02652 0.02542 0.0191 0.00314 ...\n - attr(*, \"class\")= chr \"sound\"\n\n\n \nThis function only imports files with a dynamic range of 8 or 16 bits."
  },
  {
    "objectID": "sound.html#class-audiosample-audio",
    "href": "sound.html#class-audiosample-audio",
    "title": "Sound",
    "section": "1.4 Class audioSample (audio)",
    "text": "1.4 Class audioSample (audio)\nThe audio package is another option to handle .wav files. The sound can be imported using the load.wave() function. The class of the resulting object is audioSample which is essentially a numerical vector (for mono) or a numerical matrix with two rows (for stereo). The sampling frequency and resolution are saved as attributes:\n\n\nCode\nlibrary(audio)\n\ns10 &lt;- load.wave(\"./examples/Phae.long1.wav\")\n\nhead(s10)\n\n\nsample rate: 22500Hz, mono, 16-bits\n[1]  4.943848e-03 -2.652058e-02  2.542114e-02  1.910400e-02  3.143311e-03\n[6] -6.103702e-05\n\n\nCode\ns10$rate\n\n\n[1] 22500\n\n\nCode\ns10$bits\n\n\n[1] 16\n\n\n \nThe main advantage of the audio package is that the sound can be acquired directly within an R session. This is achieved first by preparing a NAs vector and then using therecord() function. For example, to obtain a mono sound of 5 seconds sampled at 16 kHz:\n\n\nCode\ns11 &lt;- rep(NA_real_, 16000 * 5)\n\nrecord(s11, 16000, 1)\n\n\n \nA recording session can be controlled by three complementary functions: pause(), rewind(), and resume()."
  },
  {
    "objectID": "sound.html#export-sounds-from-r",
    "href": "sound.html#export-sounds-from-r",
    "title": "Sound",
    "section": "1.5 Export sounds from R",
    "text": "1.5 Export sounds from R\nFor maximum compatibility with other sound programs, it may be useful to save a sound as a simple .txt file. The following commands will write a “tico.txt” file:\n\n\nCode\ndata(tico)\n\nexport(tico, f = 22050)"
  },
  {
    "objectID": "sound.html#format-.wav",
    "href": "sound.html#format-.wav",
    "title": "Sound",
    "section": "1.6 Format ‘.wav’",
    "text": "1.6 Format ‘.wav’\ntuneR and audio have a function to write .wav files: writeWave() and save.wave() respectively. Within seewave, the savewav() function, which is based on writeWave(), can be used to save data in .wav format. By default, the object name will be used for the name of the .wav file:\n\n\nCode\nsavewav(tico)"
  },
  {
    "objectID": "sound.html#format-.flac",
    "href": "sound.html#format-.flac",
    "title": "Sound",
    "section": "1.7 Format ‘.flac’",
    "text": "1.7 Format ‘.flac’\nFree Lossless Audio Codec (FLAC) is a file format for lossless audio data compression. FLAC reduces bandwidth and storage requirements without sacrificing the integrity of the audio source. Audio sources encoded in FLAC are generally reduced in size from 40 to 50 percent. See the flac website for more details (flac.sourceforge.net).\nThe .flac format cannot be used as such with R. However, the wav2flac()function allows you to call the FLAC software directly from the console. Therefore, FLAC must be installed on your operating system. If you have a .wav file that you want to compress in .flac, call:\n\n\nCode\nwav2flac(file = \"./examples/Phae.long1.wav\", overwrite = FALSE)\n\n\n \nTo compress a .wav file to a .flac format, the argument reverse = TRUE must be used:\n\n\nCode\nwav2flac(\"Phae.long1.flac\", reverse = TRUE)\n\n\n \nThis table, taken from Sueur (2018), summarizes the functions available to import and export sound files in R. The table is incomplete since it does not mention the functions of the phonTools package:\n\n\n \n\nExercise\n\nHow does the sampling rate affect the size of an audio file? (hint: create 2 sounds files with the same data but different sampling rates; use sine())\nHow does the dynamic range affect the size of an audio file?\nUse the system.time() function to compare the performance of the different functions to import audio files in R. For this use the file “LBH.374.SUR.wav” (Long-billed hermit songs) which lasts about 2 min\n\nThe following code creates a plot similar to oscillo but using dots instead of lines:\n\n\nCode\n# generate sine wave\nwav &lt;- sine(freq = 440, duration = 500, xunit = \"samples\", samp.rate = 44100)\n\n# plot\nplot(wav@left)\n\n\n\n\n\n\n\n\n\n\n\n \n\nUse the function downsample() to reduce the sampling rate of ‘wav’ (below 44100) and plot the output object. Decrease the sampling rate until you cannot recognize the wave pattern from the original wave object. Try several values so you get a sense at which sampling rate this happens."
  },
  {
    "objectID": "sound.html#references",
    "href": "sound.html#references",
    "title": "Sound",
    "section": "1.8 References",
    "text": "1.8 References\n\nSueur J, Aubin T, Simonis C. 2008. Equipment review: seewave, a free modular tool for sound analysis and synthesis. Bioacoustics 18(2):213–226.\nSueur, J. (2018). Sound Analysis and Synthesis with R.\nSueur J. (2018). I/O of sound with R. seewave package vignette. url: https://cran.r-project.org/web/packages/seewave/vignettes/seewave_IO.pdf\n\n\nSession information\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.2 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: America/Costa_Rica\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] audio_0.1-11       phonTools_0.2-2.2  warbleR_1.1.30     NatureSounds_1.0.4\n[5] tuneR_1.4.6        knitr_1.46         seewave_2.2.3     \n\nloaded via a namespace (and not attached):\n [1] viridis_0.6.5      utf8_1.2.4         generics_0.1.3     bitops_1.0-7      \n [5] stringi_1.8.3      digest_0.6.35      magrittr_2.0.3     evaluate_0.23     \n [9] grid_4.3.2         fastmap_1.1.1      jsonlite_1.8.8     brio_1.1.4        \n[13] formatR_1.14       gridExtra_2.3      fansi_1.0.6        viridisLite_0.4.2 \n[17] scales_1.3.0       pbapply_1.7-2      cli_3.6.2          rlang_1.1.3       \n[21] fftw_1.0-8         munsell_0.5.0      withr_3.0.0        yaml_2.3.8        \n[25] tools_4.3.2        parallel_4.3.2     dplyr_1.1.4        colorspace_2.1-0  \n[29] ggplot2_3.5.1      bioacoustics_0.2.8 vctrs_0.6.5        R6_2.5.1          \n[33] proxy_0.4-27       lifecycle_1.0.4    dtw_1.23-1         stringr_1.5.1     \n[37] htmlwidgets_1.6.4  MASS_7.3-55        pkgconfig_2.0.3    pillar_1.9.0      \n[41] gtable_0.3.4       moments_0.14.1     glue_1.7.0         Rcpp_1.0.12       \n[45] xfun_0.43          tibble_3.2.1       tidyselect_1.2.0   rstudioapi_0.15.0 \n[49] rjson_0.2.21       htmltools_0.5.8.1  rmarkdown_2.26     testthat_3.2.1    \n[53] signal_1.8-0       compiler_4.3.2     RCurl_1.98-1.14"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "",
    "text": "Bioacoustic Analysis in R\n\n\nOrganization for Tropical Studies\n\n\n\nMarcelo Araya-Salas, PhD\n\n\n\nMay 13 - 17, 2024\n\n\n\n\nThe study of animal acoustic signals is a central tool for many fields in behavior, ecology, evolution and biodiversity monitoring. The accessibility of recording equipment and growing availability of open-access acoustic libraries provide an unprecedented opportunity to study animal acoustic signals at large temporal, geographic and taxonomic scales. However, the diversity of analytical methods and the multidimensionality of these signals posts significant challenges to conduct analyses that can quantify biologically meaningful variation. The recent development of acoustic analysis tools in the R programming environment provides a powerful means for overcoming these challenges, facilitating the gathering and organization of large acoustic data sets and the use of more elaborated analyses that better fit the studied acoustic signals and associated biological questions. The course will introduce students on the basic concepts in animal acoustic signal research as well as hands-on experience on analytical tools in R.\n\nObjetive\nTraining biological science students and researchers in the detection and analysis of animal sounds in R. Specifically, it seeks to familiarize participants with computational tools in the R environment aiming at curating, detecting and analyzing animal acoustic signals, with an especial focus on quantifying fine-scale structural variation. The course will introduce the most relevant acoustics concepts to allow a detailed understanding of the metrics used for characterize acoustic signals. It will also guide participants through a variety of R packages for bioacoustics analysis, including seewave, tuneR, warbleR and baRulho."
  },
  {
    "objectID": "course_prep.html",
    "href": "course_prep.html",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "",
    "text": "Install or update R on the computer you will use during the course (https://cran.r-project.org). I assume that you already have it installed, but try to update it if you have a R version &lt; 4.0.0. You can find which R version you have by running this in the R console:\n\n\nversion$version.string\n\n\nUpdate all R packages if you already had R installed (⚠️ this step can take a long time to run ⚠️):\n\n\nupdate.packages(ask = FALSE)\n\n\nInstall or update the RStudio interface (https://www.rstudio.com/products/rstudio/download/, choose the free version). Optional but advised.\nMake a directory called “BIR_OTS_2024”, this will be your working directory for the course.\nOpen RStudio and select the tab “Tools” then “Global Options” (last option). Select the “Code” option, then select the box for “Soft-wrap R source files”.\nAlso in Rstudio: Select the “Pane Layout” option and move “Source” to the top left pane and “Console” to the top right pane. For those of you unfamiliar with RStudio, the source is your script, where you save code in a physical file (usually .R script) and the console prints the output of the code you run from the source. You can write code in the console, but it will not be saved in a physical file. This layout allocates more screen space to the most useful panes. Hit “Apply” and “Ok”.\nAlso in Rstudio: Go back up to the “File” tab and select “New Project”, then select the “BIR_OTS_2024” directory.\nNow in the R console in Rstudio: Run the following code to install the latest developmental versions (from github) of warbleR, Rraven, PhenotypeSpace, ohun, baRulho and dynaSpec (remove the packages first if you have them installed already).\n\n\n# package to install other packages from github\nif (!requireNamespace(\"sketchy\"))\n  install.packages(\"sketchy\") \n\n# load package\nlibrary(sketchy)\n\n# install/load packages\nload_packages(packages = c(\n  \"pracma\",\n  \"Sim.DiffProc\",\n  \"bioacoustics\",\n  \"phonTools\",\n  \"soundgen\",\n  \"audio\",\n  github = \"maRce10/warbleR\",\n  github = \"maRce10/Rraven\",\n  github = \"maRce10/ohun\",\n  github = \"maRce10/suwo\",\n  github = \"maRce10/baRulho\",\n  github = \"maRce10/dynaSpec\"\n )\n)\n\nif you have any issue installing ‘bioacoustics’ take a look at this fix: https://stackoverflow.com/questions/53092646/unable-to-install-warbler-package-using-mac-os\n\nWe also need to install the package PhenotypeSpace, which requires some dependencies that have been archived in CRAN. So to install it please first download this two package tar.gz files and install them manually:\n\n\nrgeos_0.6-4.tar.gz\nspatstat.core_2.4-4.tar.gz\n\nOnce you have install them you can install PhenotypeSpace:\n\n# install/load package\nload_packages(packages = c(github = \"maRce10/PhenotypeSpace\"))\n\n\nwarbleR depends heavily on the R package seewave. Seewave may require some extra steps to get installed. Take a look at seewave’s website for further help: http://rug.mnhn.fr/seewave (and then go to “installation” and scroll down)\nInstall Raven lite from ttp://ravensoundsoftware.com/raven-pricing/(scroll down to “Raven Lite 2.0” and click on “Order Free Raven Lite 2.0 License”). Ignore if you have any Raven version already installed.\nInstall ffmpeg (only needed for dynaSpec package, not critical):\n\nhttps://ffmpeg.org/download.html\ntake a look at this link if you have issues installing ffmpeg on windows:\nhttps://github.com/maRce10/dynaSpec/issues/3\n\nInstall Audacity (not critical, you can use Adobe Audition instead):\n\nhttps://www.audacityteam.org/download/\n\nInstall SOX. It can be downloaded from here (not critical but could be useful): http://sox.sourceforge.net (Not critical)\nInstall FLAC. It can be downloaded from here (also not critical): https://xiph.org/flac/download.html (Not critical)\nNote that you can also run the code using google colab. Take a look at this notebook: https://colab.research.google.com/\n\n \n\nA few tips to make sure you will take full advantage of the course:\n\nSet aside a physical space, hopefully as isolated as possible from external stimuli\nUse headphones/earphones to avoid any interference from echoes or external noises\nIdeally, read the materials ahead of time (I know! it’s time comsuming)\nMake sure you have anything you need before the start of the class\nBe ready a few minutes before the start of the class\nTry to focus as much as possible in the course, close other programs or unnecessary internet browser tabs (i.e. instagram, twitter, etc). This will also make the computer more efficient (less likely to get slow)\nComment your code"
  },
  {
    "objectID": "program.html#day-3-video",
    "href": "program.html#day-3-video",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "3 Day 3 (video)",
    "text": "3 Day 3 (video)\n\n\n3.1 Additional resources\n\n3.1.1 Readings\n\nArasco, A. G., Manser, M., Watson, S. K., Kyabulima, S., Radford, A. N., Cant, M. A., & Garcia, M. (2024). Testing the acoustic adaptation hypothesis with vocalizations from three mongoose species. Animal Behaviour, 187, 71-95.\n\n\n\n \nAnnotation software annotations\n\nRaven / audacity\nOpen and explore recordings\nModify-optimize visualization parameters\nAnnotate signals\n\nQuantifying acoustic signal structure Quantify structure\n\nSpectro-temporal measurements (spectro_analysis())\nParameter description\nHarmonic content\nCepstral coefficients (mfcc_stats())\nCross-correlation (cross_correlation())\nDynamic time warping (freq_DTW())\nSignal-to-noise ratio (sig2noise())\nInflections (inflections())\nParameters at other levels (song_analysis())\n\n \n\n3.2 Homework\n\nDouble-check annotations using warbleR’s dedicated functions\n\n\nCreate single spectrograms of each annotation\nCreate full spectrograms of all sound files along with annotations\nCreate catalogs\n\n \n\nDouble-check annotations using Raven (export data from R to Raven)"
  },
  {
    "objectID": "annotations.html#objetives",
    "href": "annotations.html#objetives",
    "title": "Import annotations into R",
    "section": "Objetives",
    "text": "Objetives\n\nLearn various methods to import and export annotations in R\nGet familiar with the data structure used for representing annotations in R"
  },
  {
    "objectID": "annotations.html#annotation-tables",
    "href": "annotations.html#annotation-tables",
    "title": "Import annotations into R",
    "section": "1 Annotation tables",
    "text": "1 Annotation tables\nAn annotation table (or selection table in Raven’s terminology and warbleR) is a spreadsheet that contains information about the location (and frequency) of the sounds of interest in one or more sound files. Therefore, the basic annotation table should contain at least 3 columns:\n\n\n\n\n\nsound.files\nstart\nend\n\n\n\n\nsound_file_1.wav\n3.57\n5.78\n\n\nsound_file_1.wav\n2.29\n2.56\n\n\nsound_file_2.wav\n2.62\n4.12\n\n\nsound_file_2.wav\n2.05\n4.12\n\n\n\n\n\n\n\n \nIdeally we should also include the frequency range of the annotations:\n\n\n\n\n\nsound.files\nstart\nend\nbottom.freq\ntop.freq\n\n\n\n\nsound_file_1.wav\n3.57\n5.78\n4.86\n8.01\n\n\nsound_file_1.wav\n2.29\n2.56\n4.33\n8.20\n\n\nsound_file_2.wav\n2.62\n4.12\n5.33\n10.31\n\n\nsound_file_2.wav\n2.05\n4.12\n5.65\n10.51\n\n\n\n\n\n\n\n \n.. and a unique identifier (at least within each sound file) for each annotation:\n\n\n\n\n\nsound.files\nselec\nstart\nend\nbottom.freq\ntop.freq\n\n\n\n\nsound_file_1.wav\n1\n3.57\n5.78\n4.86\n8.01\n\n\nsound_file_1.wav\n2\n2.29\n2.56\n4.33\n8.20\n\n\nsound_file_2.wav\n1\n2.62\n4.12\n5.33\n10.31\n\n\nsound_file_2.wav\n2\n2.05\n4.12\n5.65\n10.51\n\n\n\n\n\n\n\nFinally, for sound files with multiple channels, the annotation table should indicate in which channel the sound of interest is located:\n\n\n\n\n\nsound.files\nchannel\nselec\nstart\nend\nbottom.freq\ntop.freq\n\n\n\n\nsound_file_1.wav\n1\n1\n3.57\n5.78\n4.86\n8.01\n\n\nsound_file_1.wav\n1\n2\n2.29\n2.56\n4.33\n8.20\n\n\nsound_file_2.wav\n1\n1\n2.62\n4.12\n5.33\n10.31\n\n\nsound_file_2.wav\n1\n2\n2.05\n4.12\n5.65\n10.51\n\n\n\n\n\n\n\n \nThis format, with the same column names as in the previous example, is the one used by the warbleR package as a basic data object to work on batches of sounds (“batches”). The mandatory columns are “sound.files”, “selec”, “start”, and “end”. The frequency range columns (“bottom.freq” and “top.freq”) and the channel number (“channel”) are optional.\nAnnotation tables can be generated within R, or imported from sound analysis programs (mainly, Raven, Avisoft, Syrinx and Audacity)."
  },
  {
    "objectID": "annotations.html#raven",
    "href": "annotations.html#raven",
    "title": "Import annotations into R",
    "section": "2 Raven",
    "text": "2 Raven\nRaven sound analysis software (Cornell Lab of Ornithology) provides very powerful tools for the analysis of sounds (animals). Raven allows you to use the cursor to manually define the frequency and time limits of the signals. It is a very flexible and user friendly program. The annotations can be saved in a selection file (selection table) in .txt format:\n \n\n \nSelections can be reopened on the original file where they were made:\n \n\n \nThe selections with sound (sound selection table) are a special type of annotation that contains all the information about the address of the files and allows to be opened directly without opening the sound file first. To create these selections, you must include the ‘Begin File’, ‘Begin Path’ and “File offset (s) ’columns (the latter only if the file contains annotations for more than one sound file):\n \n\n \nThese selections open easily in Raven, as long as the sound files are kept in the original folders:"
  },
  {
    "objectID": "annotations.html#rraven",
    "href": "annotations.html#rraven",
    "title": "Import annotations into R",
    "section": "3 Rraven",
    "text": "3 Rraven\n \nThe Rraven package is designed to facilitate data exchange between R and Raven sound analysis software. R can simplify the automation of complex analysis routines. In addition, R packages such as warbleR, seewave and monitorR (among others) provide additional methods of analysis, which work as a perfect complement to those found in Raven. Therefore, bridging these applications can greatly expand the bioacoustic toolkit.\nCurrently, most Raven analyzes cannot be run in the background from a command terminal. Therefore, most of the Rraven functions are designed to simplify the exchange of data between the two programs, and in some cases, export files to Raven for further analysis. This tutorial provides detailed examples for each function in Rraven, including both the R code and the additional steps required to fully conduct the analyses. Raven Pro must be installed in order to run some of the code.\nIn this link you will find several videos that show in detail the different tools in Raven.\nhttp://ravensoundsoftware.com/video-tutorials/"
  },
  {
    "objectID": "annotations.html#import-raven-data",
    "href": "annotations.html#import-raven-data",
    "title": "Import annotations into R",
    "section": "4 Import Raven data",
    "text": "4 Import Raven data\n\n4.1 imp_raven\nThis function imports Raven selection tables. You can import several files at once. Raven can also import selection tables that include data from multiple recordings. The function returns a single data frame with the information contained in the selection files. We already have 4 Raven selection tables in the example directory:\n\n\nCode\nlist.files(path = \"./examples\", pattern = \"\\\\.txt$\")\n\n\n[1] \"Label Track3.txt\"                  \"LBH 1 selection table example.txt\"\n[3] \"LBH 2 selection table example.txt\" \"LBH 3 selection table example.txt\"\n[5] \"LBH 4 selection table example.txt\"\n\n\n \nThis code shows how to import all the data contained in those files into R:\n\n\nCode\nrvn.dat &lt;- imp_raven(all.data = TRUE, path = \"./examples\")\n\nhead(rvn.dat)\n\n\n\n\n1 file(s) could not be read:  Label Track3.txt\n\n\n\n\n\n\n\nSelection\nView\nChannel\nBegin Time (s)\nEnd Time (s)\nLow Freq (Hz)\nHigh Freq (Hz)\nBegin File\nchannel\nBegin Path\nFile Offset (s)\nFile Offset\nselec.file\n\n\n\n\n1\nSpectrogram 1\n1\n1.169\n1.342\n2220\n8604\nPhae.long1.wav\n1\n/tmp/RtmpWpOeaR/Phae.long1.wav\n1.169\nNA\nLBH 1 selection table example.txt\n\n\n2\nSpectrogram 1\n1\n2.158\n2.321\n2169\n8807\nPhae.long1.wav\n1\n/tmp/RtmpWpOeaR/Phae.long1.wav\n2.158\nNA\nLBH 1 selection table example.txt\n\n\n3\nSpectrogram 1\n1\n0.343\n0.518\n2218\n8757\nPhae.long1.wav\n1\n/tmp/RtmpWpOeaR/Phae.long1.wav\n0.343\nNA\nLBH 1 selection table example.txt\n\n\n1\nSpectrogram 1\n1\n0.160\n0.292\n2317\n8822\nPhae.long2.wav\n1\n/tmp/RtmpWpOeaR/Phae.long2.wav\n0.160\nNA\nLBH 2 selection table example.txt\n\n\n2\nSpectrogram 1\n1\n1.457\n1.583\n2284\n8888\nPhae.long2.wav\n1\n/tmp/RtmpWpOeaR/Phae.long2.wav\n1.457\nNA\nLBH 2 selection table example.txt\n\n\n1\nSpectrogram 1\n1\n0.627\n0.758\n3007\n8822\nPhae.long3.wav\n1\n/tmp/RtmpWpOeaR/Phae.long3.wav\nNA\n0.627\nLBH 3 selection table example.txt\n\n\n\n\n\n\n\n\n \nNote that the ‘waveform’ view data has been deleted. It can also be imported as follows (but note that the example selection tables do not have waveform data):\n\n\nCode\nrvn.dat &lt;- imp_raven(all.data = TRUE, waveform = TRUE, path = \"./examples\")\n\n\n \nRaven selections can also be imported in ‘selection.table’ format so that you can input directly into warbleR functions. To do this, you only need to set warbler.format = TRUE:\n\n\nCode\nrvn.dat &lt;- imp_raven(all.data = FALSE, freq.cols = TRUE, path = \"./examples\", warbler.format = TRUE, all.data = FALSE)\n\nhead(rvn.dat)\n\n\n\n\n1 file(s) could not be read:  Label Track3.txt\n\n\n\n\n\n\nselec\nChannel\nstart\nend\nbottom.freq\ntop.freq\nsound.files\nchannel\nselec.file\n\n\n\n\n1\n1\n1.169355\n1.342388\n2.22011\n8.60438\nPhae.long1.wav\n1\nLBH 1 selection table example.txt\n\n\n2\n1\n2.158408\n2.321457\n2.16944\n8.80705\nPhae.long1.wav\n1\nLBH 1 selection table example.txt\n\n\n3\n1\n0.343337\n0.518255\n2.21829\n8.75660\nPhae.long1.wav\n1\nLBH 1 selection table example.txt\n\n\n1\n1\n0.159598\n0.292169\n2.31686\n8.82232\nPhae.long2.wav\n1\nLBH 2 selection table example.txt\n\n\n2\n1\n1.457058\n1.583209\n2.28401\n8.88803\nPhae.long2.wav\n1\nLBH 2 selection table example.txt\n\n\n1\n1\n0.626552\n0.757771\n3.00683\n8.82232\nPhae.long3.wav\n1\nLBH 3 selection table example.txt\n\n\n\n\n\n\n\n\n \nThe output data frame contains the following columns: “sound.files”, “channel”, “selec”, “start”, “end” and “selec.file.” You can also import the frequency range parameters in ‘selection.table’ by setting ‘freq.cols’ tp TRUE. The data frame returned by imp_raven() (when in the warbleR format) can be entered into several functions of warbleR for a more detailed analysis.\n\n\n4.2 relabel_colms\nThis is a simple function to re-label the columns to match the format of the selection table used in warbleR:\n\n\nCode\n# para simplificar solo las primeras 7 columnas\nst1 &lt;- rvn.dat[ ,1:7]\n\nst1\n\n\n\n\nCode\nrelabel_colms(st1)\n\n\n \nAdditional columns can also be re-labeled:\n\n\nCode\nrelabel_colms(st1, extra.cols.name = \"View\",\n              extra.cols.new.name = \"Raven view\")\n\n\n\n\n\n\n\n\nselec\nChannel\nstart\nend\nbottom.freq\ntop.freq\nsound.files\n\n\n\n\n1\n1\n1.169355\n1.342388\n2.22011\n8.60438\nPhae.long1.wav\n\n\n2\n1\n2.158408\n2.321457\n2.16944\n8.80705\nPhae.long1.wav\n\n\n3\n1\n0.343337\n0.518255\n2.21829\n8.75660\nPhae.long1.wav\n\n\n1\n1\n0.159598\n0.292169\n2.31686\n8.82232\nPhae.long2.wav\n\n\n2\n1\n1.457058\n1.583209\n2.28401\n8.88803\nPhae.long2.wav\n\n\n1\n1\n0.626552\n0.757771\n3.00683\n8.82232\nPhae.long3.wav\n\n\n2\n1\n1.974213\n2.104392\n2.77684\n8.88803\nPhae.long3.wav\n\n\n3\n1\n0.123364\n0.254581\n2.31686\n9.31515\nPhae.long3.wav\n\n\n1\n1\n1.516812\n1.662236\n2.51400\n9.21659\nPhae.long4.wav\n\n\n2\n1\n2.932692\n3.076878\n2.57971\n10.23512\nPhae.long4.wav\n\n\n3\n1\n0.145398\n0.290497\n2.57971\n9.74228\nPhae.long4.wav"
  },
  {
    "objectID": "annotations.html#export-r-data-to-raven",
    "href": "annotations.html#export-r-data-to-raven",
    "title": "Import annotations into R",
    "section": "5 Export R data to Raven",
    "text": "5 Export R data to Raven\n\n5.1 exp_raven\nexp_raven saves a selection table in ‘.txt’ format that can be opened directly in Raven. No objects are returned to the R environment. The following code exports a selection table from a single sound file:\n\n\nCode\nst1 &lt;- lbh_selec_table[lbh_selec_table$sound.files == \"Phae.long1.wav\",]\n\nexp_raven(st1, file.name = \"Phaethornis 1\", khz.to.hz = TRUE)\n\n\n \nIf the path to the sound file is provided, the functions export a ‘sound selection table’ that can be opened directly by Raven (and which will also open the associated sound file):\n\n\nCode\nst1 &lt;- lbh_selec_table[lbh_selec_table$sound.files == \"Phae.long1.wav\",]\n\nexp_raven(st1, file.name = \"Phaethornis 1\", khz.to.hz = TRUE, sound.file.path = \"./examples\")\n\n\n\n \nThis is useful for adding new selections or even new measurements:\n  \nIf there are several sound files available, users can export them as a single selection file or as multiple selection files (one for each sound file). This example creates a multiple selection of sound files:\n\n\nCode\nexp_raven(X = lbh_selec_table, file.name = \"Phaethornis multiple sound files\", \nsound.file.path = \"./examples\", single.file = TRUE)\n\n\n \nThese types of tables can be opened as a multi-file display in Raven:\n\n\n\nex\n\n\n \n\n \n\nExercise\n \n\nAnnotate 2 sound files from the “./examples” folder using Raven\n\n \n\nImport the annotation files into R using Rraven’s imp_raven()"
  },
  {
    "objectID": "annotations.html#warbler-formats",
    "href": "annotations.html#warbler-formats",
    "title": "Import annotations into R",
    "section": "6 warbleR formats",
    "text": "6 warbleR formats\n\n6.1 Selection tables\nThese objects are created with the selection_table() function. The function takes data frames containing selection data (name of the sound file, selection, start, end …), verifies if the information is consistent (see the function check_sels() for details) and saves the ‘diagnostic’ metadata as an attribute. The selection tables are basically data frames in which the information contained has been corroborated so it can be read by other warbleR functions. The selection tables must contain (at least) the following columns:\n\nsound files (sound.files)\nselection (selec)\nstart\nend\n\nThe sample data “lbh_selec_table” contains these columns:\n\n\nCode\nlibrary(warbleR)\n\ndata(\"lbh_selec_table\")\n\nlbh_selec_table\n\n\n\n\n\n\n\n\nsound.files\nchannel\nselec\nstart\nend\nbottom.freq\ntop.freq\n\n\n\n\nPhae.long1.wav\n1\n1\n1.169355\n1.342388\n2.22011\n8.60438\n\n\nPhae.long1.wav\n1\n2\n2.158408\n2.321457\n2.16944\n8.80705\n\n\nPhae.long1.wav\n1\n3\n0.343337\n0.518255\n2.21829\n8.75660\n\n\nPhae.long2.wav\n1\n1\n0.159598\n0.292169\n2.31686\n8.82232\n\n\nPhae.long2.wav\n1\n2\n1.457058\n1.583209\n2.28401\n8.88803\n\n\nPhae.long3.wav\n1\n1\n0.626552\n0.757771\n3.00683\n8.82232\n\n\nPhae.long3.wav\n1\n2\n1.974213\n2.104392\n2.77684\n8.88803\n\n\nPhae.long3.wav\n1\n3\n0.123364\n0.254581\n2.31686\n9.31515\n\n\nPhae.long4.wav\n1\n1\n1.516812\n1.662236\n2.51400\n9.21659\n\n\nPhae.long4.wav\n1\n2\n2.932692\n3.076878\n2.57971\n10.23512\n\n\nPhae.long4.wav\n1\n3\n0.145398\n0.290497\n2.57971\n9.74228\n\n\n\n\n\n\n\n \n… and can be converted to the selection_table format like this:\n\n\nCode\n# global parameters\nwarbleR_options(wav.path = \"./examples\")\n\nst &lt;- selection_table(X = lbh_selec_table, pb = FALSE)\n\nst\n\n\n\n\n\n\n\n\nsound.files\nchannel\nselec\nstart\nend\nbottom.freq\ntop.freq\n\n\n\n\nPhae.long1.wav\n1\n1\n1.169355\n1.342388\n2.22011\n8.60438\n\n\nPhae.long1.wav\n1\n2\n2.158408\n2.321457\n2.16944\n8.80705\n\n\nPhae.long1.wav\n1\n3\n0.343337\n0.518255\n2.21829\n8.75660\n\n\nPhae.long2.wav\n1\n1\n0.159598\n0.292169\n2.31686\n8.82232\n\n\nPhae.long2.wav\n1\n2\n1.457058\n1.583209\n2.28401\n8.88803\n\n\nPhae.long3.wav\n1\n1\n0.626552\n0.757771\n3.00683\n8.82232\n\n\nPhae.long3.wav\n1\n2\n1.974213\n2.104392\n2.77684\n8.88803\n\n\nPhae.long3.wav\n1\n3\n0.123364\n0.254581\n2.31686\n9.31515\n\n\nPhae.long4.wav\n1\n1\n1.516812\n1.662236\n2.51400\n9.21659\n\n\nPhae.long4.wav\n1\n2\n2.932692\n3.076878\n2.57971\n10.23512\n\n\nPhae.long4.wav\n1\n3\n0.145398\n0.290497\n2.57971\n9.74228\n\n\n\n\n\n\n\nNote that the path to the sound files has been provided. This is necessary in order to verify that the data provided conforms to the characteristics of the audio files.\nSelection tables have their own class in R:\n\n\nCode\nclass(st)\n\n\n[1] \"selection_table\" \"data.frame\"     \n\n\n \n\n\n6.2 Extended selection tables\nWhen the extended = TRUE argument the function generates an object of the extended_selection_table class that also contains a list of ‘wave’ objects corresponding to each of the selections in the data. Therefore, the function transforms the selection table into self-contained objects since the original sound files are no longer needed to perform most of the acoustic analysis in warbleR. This can greatly facilitate the storage and exchange of (bio)acoustic data. In addition, it also speeds up analysis, since it is not necessary to read the sound files every time the data is analyzed.\nNow, as mentioned earlier, you need the selection_table() function to create an extended selection table. You must also set the argument extended = TRUE (otherwise, the class would be a selection table). The following code converts the sample data into an extended selection table:\n\n\nCode\n#  global parameters\nwarbleR_options(wav.path = \"./examples\")\n\next_st &lt;- selection_table(X = lbh_selec_table, pb = FALSE, \n          extended = TRUE, confirm.extended = FALSE)\n\n\n\n\nWarning: 'confirm.extended' has been deprecated and will be ignored\n\n\n \nAnd that is. Now the acoustic data and the selection data (as well as the additional metadata) are all together in a single R object. The wave objects contained in the extended_selection_table can be easily extracted using the warbleR function read_sound_file:\n\n\nCode\nw1 &lt;- read_sound_file(ext_st, index = 1)\n\nw1\n\n\n\nWave Object\n    Number of Samples:      3893\n    Duration (seconds):     0.17\n    Samplingrate (Hertz):   22500\n    Channels (Mono/Stereo): Mono\n    PCM (integer format):   TRUE\n    Bit (8/16/24/32/64):    16 \n\n\n \nThe index argument indicates the row of the selection that will be read.\nThis new object class allows to share complete data sets, including acoustic data. For example, the following code downloads a subset of the data used in Araya-Salas et al (2017):\n\n\nCode\nURL &lt;- \"https://github.com/maRce10/OTS_BIR_2024/raw/master/data/extended.selection.table.araya-salas.et.al.2017.bioacoustics.100.sels.rds\"\n\ndat &lt;- readRDS(gzcon(url(URL)))\n\nnrow(dat)\n\n\n[1] 100\n\n\nCode\nformat(object.size(dat), units = \"auto\")\n\n\n[1] \"10.1 Mb\"\n\n\nThe total size of the 100 sound files from which these selections were taken adds up to 1.1 GB. The size of the extended selection table is only 10.1 MB.\nThis data is ready to be used. For instance, here I create a multipanel graph with the spectrograms of the first 6 selections:\n\n\nCode\npar(mfrow = c(3, 2), mar = rep(0, 4))\n\nfor(i in 1:6){\n  \n  wv &lt;- read_wave(X = dat, index = i, from = 0.17, to = 0.4)\n\n  spectro(\n    wv,\n    wl = 250,\n    grid = FALSE,\n    scale = FALSE,\n    axisX = FALSE,\n    axisY = FALSE,\n    ovlp = 90,\n    flim = c(0, 12),\n    palette = viridis::viridis,\n    collevels = seq(-120, 0, 5)\n      \n  )\n}\n\n\n\n\n\n\n\n\n\n \n\nExercise\n \n\nRun the example code in the selection_table() function documentation\nWhat do the arguments “mar” and “by.song” from selection_table() do?\nMeasure the peak frequency of the 8th selection (hint: use seewave’s fpeaks())"
  },
  {
    "objectID": "annotations.html#references",
    "href": "annotations.html#references",
    "title": "Import annotations into R",
    "section": "7 References",
    "text": "7 References\n\nAraya-Salas (2017), Rraven: connecting R and Raven bioacoustic software. R package version 1.0.2.\n\n\n \nSession information\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.2 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       \n [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C              \n[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: America/Costa_Rica\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] kableExtra_1.3.4   warbleR_1.1.30     NatureSounds_1.0.4 knitr_1.46         seewave_2.2.3     \n[6] tuneR_1.4.6       \n\nloaded via a namespace (and not attached):\n [1] viridis_0.6.5     generics_0.1.3    utf8_1.2.4        bitops_1.0-7      xml2_1.3.6       \n [6] stringi_1.8.3     digest_0.6.35     magrittr_2.0.3    evaluate_0.23     grid_4.3.2       \n[11] fastmap_1.1.1     jsonlite_1.8.8    brio_1.1.4        gridExtra_2.3     httr_1.4.7       \n[16] rvest_1.0.3       fansi_1.0.6       viridisLite_0.4.2 scales_1.3.0      pbapply_1.7-2    \n[21] cli_3.6.2         rlang_1.1.3       fftw_1.0-8        munsell_0.5.0     yaml_2.3.8       \n[26] tools_4.3.2       parallel_4.3.2    dplyr_1.1.4       colorspace_2.1-0  Rraven_1.0.13    \n[31] ggplot2_3.5.1     webshot_0.5.5     vctrs_0.6.5       R6_2.5.1          proxy_0.4-27     \n[36] lifecycle_1.0.4   dtw_1.23-1        stringr_1.5.1     htmlwidgets_1.6.4 MASS_7.3-55      \n[41] pkgconfig_2.0.3   pillar_1.9.0      gtable_0.3.4      glue_1.7.0        Rcpp_1.0.12      \n[46] systemfonts_1.0.5 tidyselect_1.2.0  tibble_3.2.1      xfun_0.43         highr_0.10       \n[51] rstudioapi_0.15.0 rjson_0.2.21      htmltools_0.5.8.1 rmarkdown_2.26    svglite_2.1.3    \n[56] testthat_3.2.1    signal_1.8-0      compiler_4.3.2    RCurl_1.98-1.14"
  },
  {
    "objectID": "program.html#day-4-video",
    "href": "program.html#day-4-video",
    "title": "OTS Bioacoustic Analysis in R 2024",
    "section": "4 Day 4 (video)",
    "text": "4 Day 4 (video)\n\n\n4.1 Additional resources\n\n4.1.1 Readings\n\nOdom, K. J., Cain, K. E., Hall, M. L., Langmore, N. E., Mulder, R. A., Kleindorfer, S., … & Webster, M. S. (2021). Sex role similarity and sexual selection predict male and female song elaboration and dimorphism in fairy‐wrens. Ecology and evolution, 11(24), 17901-17919.\n\n\n\n \nQuality control in recordings and annotations Quality checks\n\nCheck and modify sound file format (check_wavs(), info_wavs(), duration_wavs(), mp32wav() y fix_wavs())\nTuning spectrogram parameters (tweak_spectro())\nDouble-checking selection tables (check_sels(), spectrograms(), full_spectrograms() & catalog())\nRe-adjusting selections (tailor_sels())\n\nCharacterizing hierarchical levels in acoustic signals\n\nCreating ‘song’ spectrograms (full_spectrograms(), spectrograms())\n‘Song’ parameters (song_analysis())\n\n \n\n4.2 Homework\n\nSelect best quality signals for analysis\nMeasure acoustic parameters\nSummarize variation at higher hierachical levels (if necessary)"
  },
  {
    "objectID": "quality_checks.html",
    "href": "quality_checks.html",
    "title": "Quality checks for recordings and annotations",
    "section": "",
    "text": "When working with sound files obtained from various sources it is common to have variation in recording formats and parameters or even find corrupt files. Similarly, when a large number of annotations are used, it is normal to find errors in some of them. These problems may prevent the use of acoustic analysis in warbleR. Luckily, the package also offers functions to facilitate the detection and correction of errors in sound files and annotations."
  },
  {
    "objectID": "quality_checks.html#objetive",
    "href": "quality_checks.html#objetive",
    "title": "Quality checks for recordings and annotations",
    "section": "Objetive",
    "text": "Objetive\n\nProvide tools for double-checking the quality of the acoustic data and derived analyses along the acoustic analysis workflow"
  },
  {
    "objectID": "quality_checks.html#convert-.mp3-to-.wav",
    "href": "quality_checks.html#convert-.mp3-to-.wav",
    "title": "Quality checks for recordings and annotations",
    "section": "1 Convert .mp3 to .wav",
    "text": "1 Convert .mp3 to .wav\nThe mp32wav() function allows you to convert files in ‘.mp3’ format to ‘.wav’ format. This function converts all the ‘mp3’ files in the working directory. Let’s use the files in the ‘./examples/mp3’ folder as an example:\n\n\nCode\nwarbleR_options(wav.path = \"./examples\", ovlp = 90)\n\nlist.files(path = \"./examples/mp3\", pattern = \"mp3$\")\n\nmp32wav(path = \"./examples/mp3\", dest.path = \"./examples/mp3\")\n\nlist.files(path = \"./examples/mp3\", pattern = \"mp3$|wav$\")\n\n\n\n\n[1] \"BlackCappedVireo.mp3\" \"BowheadWhaleSong.mp3\" \"CanyonWren.mp3\"      \n\n\n[1] \"BlackCappedVireo.mp3\" \"BlackCappedVireo.wav\" \"BowheadWhaleSong.mp3\"\n[4] \"BowheadWhaleSong.wav\" \"CanyonWren.mp3\"       \"CanyonWren.wav\"      \n\n\n \nWe can also modify the sampling rate and/or dynamic range with mp32wav():\n\n\nCode\nmp32wav(path = \"./examples/mp3\", samp.rate = 48, bit.depth = 24, overwrite = TRUE,\n    dest.path = \"./examples/mp3\")\n\nlist.files(path = \"./examples/mp3\")\n\n\n \nWe can check the properties of the ‘.wav’ sound files using the info_sound_files() function:\n\n\nCode\ninfo_sound_files(path = \"./examples/mp3\")\n\n\n\n\n\n\n\nsound.files\nduration\nsample.rate\nchannels\nbits\nwav.size\nsamples\n\n\n\n\nBlackCappedVireo.mp3\n5.459592\n22.05\n1\n16\n0.087770\n120384\n\n\nBlackCappedVireo.wav\n5.459592\n22.05\n1\n16\n0.240812\n120384\n\n\nBowheadWhaleSong.mp3\n86.648163\n22.05\n1\n16\n1.386787\n1910592\n\n\nBowheadWhaleSong.wav\n86.648163\n22.05\n1\n16\n3.821228\n1910592\n\n\nCanyonWren.mp3\n5.433469\n44.10\n1\n16\n0.087352\n239616\n\n\nCanyonWren.wav\n5.433469\n44.10\n1\n16\n0.479276\n239616"
  },
  {
    "objectID": "quality_checks.html#homogenize-recordings",
    "href": "quality_checks.html#homogenize-recordings",
    "title": "Quality checks for recordings and annotations",
    "section": "2 Homogenize recordings",
    "text": "2 Homogenize recordings\nAlternatively, we can use the fix_wavs() function to homogenize the sampling rate, the dynamic interval and the number of channels. It is adviced that all sound files should have the same recording parameters before any acoustic analysis. In the example ‘.mp3’ files, not all of them have been recorded with the same parameters. We can see this if we convert them back to ‘.wav’ and see their properties:\n\n\nCode\nmp32wav(path = \"./examples/mp3\", overwrite = TRUE, dest.path = \"./examples/mp3\"\n\ninfo_sound_files(path = \"./examples/mp3\")\n\n\n\n\n\n\n\nsound.files\nduration\nsample.rate\nchannels\nbits\nwav.size\nsamples\n\n\n\n\nBlackCappedVireo.mp3\n5.459592\n22.05\n1\n16\n0.087770\n120384\n\n\nBlackCappedVireo.wav\n5.459592\n22.05\n1\n16\n0.240812\n120384\n\n\nBowheadWhaleSong.mp3\n86.648163\n22.05\n1\n16\n1.386787\n1910592\n\n\nBowheadWhaleSong.wav\n86.648163\n22.05\n1\n16\n3.821228\n1910592\n\n\nCanyonWren.mp3\n5.433469\n44.10\n1\n16\n0.087352\n239616\n\n\nCanyonWren.wav\n5.433469\n44.10\n1\n16\n0.479276\n239616\n\n\n\n\n\n\n\n \nThe fix_wavs() function will convert all files to the same sampling rate and dynamic range:\n\n\nCode\nfix_wavs(path = mp3.pth, samp.rate = 44.1, bit.depth = 24)\n\ninfo_sound_files(path = \"./examples/mp3/converted_sound_files\")\n\n\n\n\n\n\n\nsound.files\nduration\nsample.rate\nchannels\nbits\nwav.size\nsamples\n\n\n\n\nBlackCappedVireo.mp3\n5.459592\n22.05\n1\n16\n0.087770\n120384\n\n\nBlackCappedVireo.wav\n5.459592\n22.05\n1\n16\n0.240812\n120384\n\n\nBowheadWhaleSong.mp3\n86.648163\n22.05\n1\n16\n1.386787\n1910592\n\n\nBowheadWhaleSong.wav\n86.648163\n22.05\n1\n16\n3.821228\n1910592\n\n\nCanyonWren.mp3\n5.433469\n44.10\n1\n16\n0.087352\n239616\n\n\nCanyonWren.wav\n5.433469\n44.10\n1\n16\n0.479276\n239616\n\n\n\n\n\n\n\nAnother useful function to check file properties is wav_dur(). This function returns the duration in seconds of each ‘.wav’ file."
  },
  {
    "objectID": "quality_checks.html#check-recordings",
    "href": "quality_checks.html#check-recordings",
    "title": "Quality checks for recordings and annotations",
    "section": "3 Check recordings",
    "text": "3 Check recordings\ncheck_sound_files() should be the first function that should be used before running any warbleR analysis. The function simply checks if the sound files in ‘.wav’ format in the working directory can be read in R. For example, the following code checks all the files in the ‘examples’ folder, which should detect the ‘corrupted_file.wav’:\n\n\nCode\ncheck_sound_files()\n\n\nIf we remove that file from the folder, the function returns the following message:\n\n\nCode\ncheck_sound_files()"
  },
  {
    "objectID": "quality_checks.html#spectrograph-settings",
    "href": "quality_checks.html#spectrograph-settings",
    "title": "Quality checks for recordings and annotations",
    "section": "4 Spectrograph settings",
    "text": "4 Spectrograph settings\nThe parameters that determine the appearance of spectrograms (and power spectra and periodgrams) also have an effect on the measurements taken on them. Therefore it is necessary to use the same parameters to analyze all the signals in a project (except with some exceptions) so that the measurements are comparable. The visualization of spectrograms generated with different spectrographic parameters is a useful way of defining the combination of parameters with which the structure of the signals is distinguished in more detail. The function tweak_spectro() aims to simplify the selection of parameters through the display of spectrograms. The function plots, for a single selection, a mosaic of spectrograms with different display parameters. For numerical arguments, the upper and lower limits of a range can be provided. The following parameters may have variable values:\n\nwl: window length (numerical range)\novlp: overlap (numerical range)\ncollev.min: minimum amplitude value for color levels (numerical range)\nwn: window function name (character)\npal: palette (character)\n\nThe following code generates an image with spectrograms that vary in window size and window function (the rest of the parameters are passed to the catalog () function internally to create the mosaic):\n\n\nCode\ntweak_spectro(X = lbh_selec_table, wl = c(100, 1000), wn = c(\"hanning\",\n    \"hamming\", \"rectangle\"), length.out = 16, nrow = 8, ncol = 6,\n    width = 15, height = 20, rm.axes = TRUE, cex = 1, box = F)\n\n\n\n \nNote that the length.out argument defines the number of values to interpolate within the numerical ranges. wl = 220 seems to produce clearer spectrograms.\nWe can add a color palette to differentiate the levels of one of the parameters, for example ‘wn’:\n\n\nCode\n# install.packages('RColorBrewer')\n\nlibrary(RColorBrewer)\n\n# crear paleta\ncmc &lt;- function(n) if (n &gt; 5) rep(adjustcolor(brewer.pal(5, \"Spectral\"),\n    alpha.f = 0.6), ceiling(n/4))[1:n] else adjustcolor(brewer.pal(n,\n    \"Spectral\"), alpha.f = 0.6)\n\ntweak_spectro(X = lbh_selec_table, wl = c(100, 1000), wn = c(\"hanning\",\n    \"hamming\", \"rectangle\"), length.out = 16, nrow = 8, ncol = 6,\n    width = 15, height = 20, rm.axes = TRUE, cex = 1, box = F, group.tag = \"wn\",\n    tag.pal = list(cmc))\n\n\n\n \nWe can also use it to choose the color palette and the minimum amplitude for plotting (‘collev.min’):\n\n\nCode\ntweak_spectro(X = lbh_selec_table, wl = 220, collev.min = c(-20, -100),\n    pal = c(\"reverse.gray.colors.2\", \"reverse.topo.colors\", \"reverse.terrain.colors\"),\n    length.out = 16, nrow = 8, ncol = 6, width = 15, height = 20,\n    rm.axes = TRUE, cex = 1, box = F, group.tag = \"pal\", tag.pal = list(cmc))"
  },
  {
    "objectID": "quality_checks.html#double-check-selections",
    "href": "quality_checks.html#double-check-selections",
    "title": "Quality checks for recordings and annotations",
    "section": "5 Double-check selections",
    "text": "5 Double-check selections\nThe main function to double-check selection tables is check_sels(). This function checks a large number of possible errors in the selection information:\n\n‘X’ is an object of the class ‘data.frame’ or ‘selection_table’ (see selection_table) and contains the columns required to be used in any warbleR function (‘sound.files’, ‘selec’, ‘start’ , ‘end’, if it does not return an error)\n‘sound.files’ in ‘X’ corresponds to the .wav files in the working directory or in the provided ‘path’ (if no file is found it returns an error, if some files are not found it returns error information in the output data frame)\nthe time limit parameters (‘start’, ‘end’) and frequency (‘bottom.freq’, ‘top.freq’, if provided) are numeric and do not contain NA (if they do not return an error)\nThere are no duplicate selection tags (‘selec’) within a sound file (if it does not return an error)\nsound files can be read (error information in the output data frame)\nThe start and end time of the selections is within the duration of the sound files (error information in the output data frame)\nSound files can be read (error information in the output data frame)\nThe header (header) of the sound files is not damaged (only if the header = TRUE, error information in the selection table with results)\n‘top.freq’ is less than half of the sampling frequency (nyquist frequency, error information in the data table with results)\nNegative values are not found in the time or frequency limit parameters (error information in the data table with results)\n‘start’ higher than ‘end’ or ‘bottom.freq’ higher than ‘top.freq’ (error information in the output data frame)\nThe value of ‘channel’ is not greater than the number of channels in the sound files (error information in the output data frame)\n\n\n\nCode\ncs &lt;- check_sels(lbh_selec_table)\n\n\n \nThe function returns a data frame that includes the information in ‘X’ plus additional columns about the format of the sound files, as well as the result of the checks (column ‘check.res’):\n\n\nCode\ncs\n\n\n\n\n\n\n\n\nsound.files\nchannel\nselec\nstart\nend\nbottom.freq\ntop.freq\ncheck.res\nduration\nmin.n.samples\nsample.rate\nchannels\nbits\nsound.file.samples\n\n\n\n\nPhae.long1.wav\n1\n1\n1.1693549\n1.3423884\n2.220105\n8.604378\nOK\n0.1730334\n3893\n22.5\n1\n16\n56251\n\n\nPhae.long1.wav\n1\n2\n2.1584085\n2.3214565\n2.169437\n8.807053\nOK\n0.1630480\n3668\n22.5\n1\n16\n56251\n\n\nPhae.long1.wav\n1\n3\n0.3433366\n0.5182553\n2.218294\n8.756604\nOK\n0.1749187\n3935\n22.5\n1\n16\n56251\n\n\nPhae.long2.wav\n1\n1\n0.1595983\n0.2921692\n2.316862\n8.822316\nOK\n0.1325709\n2982\n22.5\n1\n16\n38251\n\n\nPhae.long2.wav\n1\n2\n1.4570585\n1.5832087\n2.284006\n8.888027\nOK\n0.1261502\n2838\n22.5\n1\n16\n38251\n\n\nPhae.long3.wav\n1\n1\n0.6265520\n0.7577715\n3.006834\n8.822316\nOK\n0.1312195\n2952\n22.5\n1\n16\n49500\n\n\nPhae.long3.wav\n1\n2\n1.9742132\n2.1043921\n2.776843\n8.888027\nOK\n0.1301789\n2929\n22.5\n1\n16\n49500\n\n\nPhae.long3.wav\n1\n3\n0.1233643\n0.2545812\n2.316862\n9.315153\nOK\n0.1312170\n2952\n22.5\n1\n16\n49500\n\n\nPhae.long4.wav\n1\n1\n1.5168116\n1.6622365\n2.513997\n9.216586\nOK\n0.1454249\n3272\n22.5\n1\n16\n72000\n\n\nPhae.long4.wav\n1\n2\n2.9326920\n3.0768784\n2.579708\n10.235116\nOK\n0.1441864\n3244\n22.5\n1\n16\n72000\n\n\nPhae.long4.wav\n1\n3\n0.1453977\n0.2904966\n2.579708\n9.742279\nOK\n0.1450989\n3264\n22.5\n1\n16\n72000\n\n\n\n\n\n\n\n \nLet’s modified a selection table to see how the function works:\n\n\nCode\n# copiar las primeras 6 filas\nst2 &lt;- lbh_selec_table[1:6, ]\n\n# hacer caracter\nst2$sound.files &lt;- as.character(st2$sound.files)\n\n# cambiar nombre de archivo de sonido en sel 1\nst2$sound.files[1] &lt;- \"aaa.wav\"\n\n# modificar fin en sel 3\nst2$end[3] &lt;- 100\n\n# hacer top.freq igual q bottom freq en sel 3\nst2$top.freq[3] &lt;- st2$bottom.freq[3]\n\n# modificar top freq en sel 5\nst2$top.freq[5] &lt;- 200\n\n# modificar channes en sel 6\nst2$channel[6] &lt;- 3\n\n# revisar\ncs &lt;- check_sels(st2)\n\ncs[, c(1:7, 10)]\n\n\n\n\n\n\n\nsound.files\nchannel\nselec\nstart\nend\nbottom.freq\ntop.freq\nmin.n.samples\n\n\n\n\naaa.wav\n1\n1\n1.1693549\n1.3423884\n2.220105\n8.604378\nNA\n\n\nPhae.long1.wav\n1\n2\n2.1584085\n2.3214565\n2.169437\n8.807053\n3668\n\n\nPhae.long1.wav\n1\n3\n0.3433366\n100.0000000\n2.218294\n2.218294\n2242274\n\n\nPhae.long2.wav\n1\n1\n0.1595983\n0.2921692\n2.316862\n8.822316\n2982\n\n\nPhae.long2.wav\n1\n2\n1.4570585\n1.5832087\n2.284006\n200.000000\n2838\n\n\nPhae.long3.wav\n1\n1\n0.6265520\n0.7577715\n3.006834\n8.822316\n2952\n\n\n\n\n\n\n\n \ncheck_sels() is used internally when creating selection tables and extended selection tables.\n \n\n5.1 Visual inspection of spectrograms\nOnce the information in the selections has been verified, the next step is to ensure that the selections contain accurate information about the location of the signals of interest. This can be done by creating spectrograms of all selections. For this we have several options. The first is spectrograms() (previously called specreator()) which generates (by default) a spectrogram for each selection. We can run it on the sample data like this:\n\n\nCode\n# using default parameters tweak_spectro()\nwarbleR_options(wav.path = \"./examples\", wl = 220, wn = \"hanning\",\n    ovlp = 90, pal = reverse.topo.colors)\n\nspectrograms(lbh_selec_table, collevels = seq(-100, 0, 5))\n\n\n \nThe images it produces are saved in the working directory and look like this:\n\n \n\nExercise\n \n\nHave the label shown on the selection display the data in the ‘sel.comment’ column of the sample selection box using the sel.labels argument\n\n\n \n\n\n5.2 Full spectrograms\nWe can create spectrograms for the whole sound files using full_spectrograms(). If the X argument is not given, the function will create the spectrograms for all the files in the working directory. Otherwise, the function generates spectrograms for sound files in X and highlights selections with transparent rectangles similar to those ofspectrograms(). In this example we download a recording from a striped-throated hermit (Phaethornis striigularis) from Xeno-Canto:\n\n\nCode\n# load package with color palettes\nlibrary(viridis)\n\n# create directory\ndir.create(\"./examples/hermit\")\n\n# download sound file\nphae.stri &lt;- query_xc(qword = \"nr:154074\", download = TRUE, path = \"./examples/hermit\")\n\n# Convert mp3 to wav format\nmp32wav(path = \"./examples/hermit/\", pb = FALSE)\n\n# plot full spec\nfull_spectrograms(sxrow = 1, rows = 10, pal = magma, wl = 200, flim = c(3,\n    10), collevels = seq(-140, 0, 5), path = \"./examples/hermit/\")"
  },
  {
    "objectID": "quality_checks.html#catalogs",
    "href": "quality_checks.html#catalogs",
    "title": "Quality checks for recordings and annotations",
    "section": "6 Catalogs",
    "text": "6 Catalogs\nCatalogs allow you to inspect selections of many recordings in the same image and group them by categories. This makes it easier to verify the consistency of the categories. Many of the arguments are shared with tweak_spectro() (catalog() is used internally in tweak_spectro()). We can generate a catalog with color tags to identify selections from the same sound file as follows:\n\n\nCode\n# read bat inquiry data\ninq &lt;- readRDS(file = \"ext_sel_tab_inquiry.RDS\")\n\ncatalog(X = inq[1:100, ], flim = c(10, 50), nrow = 10, ncol = 10,\n    same.time.scale = T, mar = 0.01, gr = FALSE, img.suffix = \"inquiry\",\n    labels = c(\"sound.files\", \"selec\"), legend = 0, rm.axes = TRUE,\n    box = F, group.tag = \"sound.files\", tag.pal = list(magma), width = 20,\n    height = 20, pal = viridis, collevels = seq(-100, 0, 5))\n\n\n\n \n\nExercise\n \n\nUsing the ‘lbh_selec_table’ data, create a catalog with selections color-tagged by song type"
  },
  {
    "objectID": "quality_checks.html#tailoring-selections",
    "href": "quality_checks.html#tailoring-selections",
    "title": "Quality checks for recordings and annotations",
    "section": "7 Tailoring selections",
    "text": "7 Tailoring selections\nThe position of the selections in the sound file (i.e. its ‘coordinates’ of time and frequency) can be modified interactively from R using the sel_tailor() function. This function produces a graphic window showing spectrograms and a series of ‘buttons’ that allow you to modify the view and move forward in the selection table:\n\n\nCode\ntailor_sels(X = lbh_selec_table[1:4, ], auto.next = TRUE)\n\n\n\n \nThe function returns the corrected data as a data frame in R and also saves a ‘.csv’ file in the directory where the sound files are located.\nsel_tailor() can also be used to modify frequency contours such as those produced by the dfDTW() or ffDTW() function:\n\n\nCode\ncntours &lt;- freq_ts(X = lbh_selec_table[1:5, ])\n\ntail.cntours &lt;- tailor_sels(X = lbh_selec_table[1:5, ], ts.df = cntours,\n    auto.contour = TRUE)"
  },
  {
    "objectID": "quality_checks.html#references",
    "href": "quality_checks.html#references",
    "title": "Quality checks for recordings and annotations",
    "section": "8 References",
    "text": "8 References\n\nAraya-Salas M, Smith-Vidaurre G (2017) warbleR: An R package to streamline analysis of animal acoustic signals. Methods Ecol Evol 8:184–191.\n\n \n\nSession information\n\n\nR version 4.3.2 (2023-10-31)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.2 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: America/Costa_Rica\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] kableExtra_1.3.4   warbleR_1.1.30     NatureSounds_1.0.4 knitr_1.46        \n[5] seewave_2.2.3      tuneR_1.4.6       \n\nloaded via a namespace (and not attached):\n [1] jsonlite_1.8.8     compiler_4.3.2     rjson_0.2.21       brio_1.1.4        \n [5] webshot_0.5.5      Rcpp_1.0.12        xml2_1.3.6         stringr_1.5.1     \n [9] moments_0.14.1     bitops_1.0-7       parallel_4.3.2     signal_1.8-0      \n[13] systemfonts_1.0.5  scales_1.3.0       yaml_2.3.8         fastmap_1.1.1     \n[17] R6_2.5.1           dtw_1.23-1         htmlwidgets_1.6.4  MASS_7.3-55       \n[21] munsell_0.5.0      svglite_2.1.3      rlang_1.1.3        testthat_3.2.1    \n[25] stringi_1.8.3      xfun_0.43          fftw_1.0-8         viridisLite_0.4.2 \n[29] cli_3.6.2          withr_3.0.0        formatR_1.14       magrittr_2.0.3    \n[33] bioacoustics_0.2.8 digest_0.6.35      rvest_1.0.3        rstudioapi_0.15.0 \n[37] pbapply_1.7-2      lifecycle_1.0.4    vctrs_0.6.5        proxy_0.4-27      \n[41] evaluate_0.23      glue_1.7.0         RCurl_1.98-1.14    colorspace_2.1-0  \n[45] rmarkdown_2.26     httr_1.4.7         tools_4.3.2        htmltools_0.5.8.1"
  }
]